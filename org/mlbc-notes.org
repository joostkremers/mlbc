#+TITLE: Notes on "Machine Learning Bookcamp"
#+PROPERTY: header-args:python+ :exports both :eval never-export
#+HTML_HEAD: <link rel="stylesheet" type="text/css" href="styles/readtheorg_theme/css/htmlize.css"/>
#+HTML_HEAD: <link rel="stylesheet" type="text/css" href="styles/readtheorg_theme/css/readtheorg.css"/>
#+HTML_HEAD: <script type="text/javascript" src="styles/lib/js/jquery.min.js"></script>
#+HTML_HEAD: <script type="text/javascript" src="styles/lib/js/bootstrap.min.js"></script>
#+HTML_HEAD: <script type="text/javascript" src="styles/lib/js/jquery.stickytableheaders.min.js"></script>
#+HTML_HEAD: <script type="text/javascript" src="styles/readtheorg_theme/js/readtheorg.js"></script>
#+STARTUP: overview

* Setup                                                            :noexport:

** Run the code in a virtual environment:

#+begin_src emacs-lisp :results silent
  (pcase system-type
    ('gnu/linux (pyvenv-workon "mlbc-3mO1CerA-py3.9"))
    ('windows-nt (pyvenv-workon "mlbc-IuAdIQfB-py3.9")))
#+end_src

To access the utility functions, first tangle this file with =C-c C-v t=. This
creates a file =mlutils.py= in the current directory, which can then be imported
(from).

** Image support

#+NAME: savefig
#+BEGIN_SRC python :results file :exports none
  # The =path= variable must be set by the block that expands this org source code
  # block:

  plt.savefig(path)
  plt.clf()
  path
#+END_SRC


* Chapter 2: Machine Learning for Regression

** Notes to chapter 2                                             :noexport:
:PROPERTIES:
:header-args:python+: :session ch2-notes
:END:

*** Imports

#+begin_src python :results silent
  import pandas as pd
  import numpy as np

  from matplotlib import pyplot as plt
  import seaborn as sns
#+end_src

*** Reading and preparing the data

#+begin_src python :results value
  df = pd.read_csv('../data/cars.csv')
  len(df)
#+end_src

#+RESULTS:
: 11914

#+begin_src python
  df.head()
#+end_src

#+RESULTS:
:   Make       Model  Year             Engine Fuel Type  ...  highway MPG  city mpg Popularity   MSRP
: 0  BMW  1 Series M  2011  premium unleaded (required)  ...           26        19       3916  46135
: 1  BMW    1 Series  2011  premium unleaded (required)  ...           28        19       3916  40650
: 2  BMW    1 Series  2011  premium unleaded (required)  ...           28        20       3916  36350
: 3  BMW    1 Series  2011  premium unleaded (required)  ...           28        18       3916  29450
: 4  BMW    1 Series  2011  premium unleaded (required)  ...           28        18       3916  34500
:
: [5 rows x 16 columns]

#+begin_src python
  df.dtypes
#+end_src

#+RESULTS:
#+begin_example
Make                  object
Model                 object
Year                   int64
Engine Fuel Type      object
Engine HP            float64
Engine Cylinders     float64
Transmission Type     object
Driven_Wheels         object
Number of Doors      float64
Market Category       object
Vehicle Size          object
Vehicle Style         object
highway MPG            int64
city mpg               int64
Popularity             int64
MSRP                   int64
dtype: object
#+end_example

Cleaning up the data:

#+begin_src python :results silent
  df.columns = df.columns.str.lower().str.replace(' ', '_')

  string_columns = list(df.dtypes[df.dtypes == 'object'].index)

  for col in string_columns:
      df[col] = df[col].str.lower().str.replace(' ', '_')
#+end_src

#+begin_src python
  df.head()
#+end_src

#+RESULTS:
:   make       model  year             engine_fuel_type  engine_hp  engine_cylinders transmission_type  ...                        market_category  vehicle_size vehicle_style highway_mpg city_mpg  popularity   msrp
: 0  bmw  1_series_m  2011  premium_unleaded_(required)      335.0               6.0            manual  ...  factory_tuner,luxury,high-performance       compact         coupe          26       19        3916  46135
: 1  bmw    1_series  2011  premium_unleaded_(required)      300.0               6.0            manual  ...                     luxury,performance       compact   convertible          28       19        3916  40650
: 2  bmw    1_series  2011  premium_unleaded_(required)      300.0               6.0            manual  ...                luxury,high-performance       compact         coupe          28       20        3916  36350
: 3  bmw    1_series  2011  premium_unleaded_(required)      230.0               6.0            manual  ...                     luxury,performance       compact         coupe          28       18        3916  29450
: 4  bmw    1_series  2011  premium_unleaded_(required)      230.0               6.0            manual  ...                                 luxury       compact   convertible          28       18        3916  34500
:
: [5 rows x 16 columns]

- Notes:
  - =df.dtypes= gives a list of types, =df.dtypes[df.dtypes == 'object']= lists
    only those that have the given type.
  - =df.dtypes.index= gives an Index object listing all the relevant columns.
  - The =str= attribute makes it possible to apply string operations to all the
    elements in the column at once.

#+begin_src python :results file figures/figure2-01.png
  sns.displot(df.msrp, kde=False)
  plt.savefig('figures/figure2-01.png')
  'figures/figure2-01.png'
#+end_src

#+RESULTS:
[[file:figures/figure2-01.png]]

#+begin_src python :results file figures/figure2-02.png
  sns.displot(df.msrp[df.msrp < 100000], kde=False)
  plt.savefig('figures/figure2-02.png')
  'figures/figure2-02.png'
#+end_src

#+RESULTS:
[[file:figures/figure2-02.png]]

This kind of distribution is difficult for machine learning algorithms, esp.
linear regression, because of the long tail of high prices, which occur
relatively rarely, but must still be learned.

The common solution in such cases is to apply a logarithm transformation to the
*target value*:

y_{new} = log(y+1)

Adding 1 to the original target value avoids calculating log(0) = -∞. Numpy has
a function for this purpose, =np.log1p=:

#+begin_src python :results file figures/figure2-03.png
  log_price = np.log1p(df.msrp)
  sns.displot(log_price)
  plt.savefig('figures/figure2-03.png')
  'figures/figure2-03.png'
#+end_src

#+RESULTS:
[[file:figures/figure2-03.png]]

This so-called "normal or Gaussian distribution" is more amenable to machine
learning algorithms.

Note that there are a lot of empty cells in the dataframe. These need to be
dealt with (see below):

#+begin_src python
  df.isnull().sum()
#+end_src

#+RESULTS:
#+begin_example
make                    0
model                   0
year                    0
engine_fuel_type        3
engine_hp              69
engine_cylinders       30
transmission_type       0
driven_wheels           0
number_of_doors         6
market_category      3742
vehicle_size            0
vehicle_style           0
highway_mpg             0
city_mpg                0
popularity              0
msrp                    0
dtype: int64
#+end_example

*** Setting up the validation framework

*** Splitting the data into a train, a validation and a test set
- 20% for validation
- 20% for testing
- 60% for training

#+begin_src python :results silent
  n = len(df)

  n_val = int(0.2 * n)
  n_test = int(0.2 * n)
  n_train = n - (n_val + n_test)

  np.random.seed(2)
  idx = np.arange(n)
  np.random.shuffle(idx)

  df_shuffled = df.iloc[idx]

  df_train = df_shuffled.iloc[:n_train].copy()
  df_val = df_shuffled.iloc[n_train:n_train+n_val].copy()
  df_test = df_shuffled.iloc[n_train+n_val:].copy()
#+end_src

We still need to apply the log transformation:

#+begin_src python :results silent
  y_train = np.log1p(df_train.msrp.values)
  y_val = np.log1p(df_val.msrp.values)
  y_test = np.log1p(df_test.msrp.values)
#+end_src

The target value should be removed from the dataframes, just in case:

#+begin_src python :results silent
  del df_train['msrp']
  del df_val['msrp']
  del df_test['msrp']
#+end_src

*** Training the model

**** Linear regression

Computing the weights =w= can be done with the "normal equation":

w = (X^{T}·X)^{-1}·X^{T}·y

where:

- X is a matrix of input features
- y is a vector of target values
- X^{T} is the *transpose* of X (=X.T= in Numpy)
- X^{-1} is the *inverse* of X (=np.linalg.inv= in Numpy)


The dot product in Numpy is obtained with the =dot()= method. Thus, the formula
above becomes:

#+begin_src python
w = inv(X.T.dot(X)).dot(X.T).dot(y)
#+end_src

**** Implementing the normal equation

In Python:

#+begin_src python :results silent
  def linear_regression(X, y):
      # X: matrix of features
      # y: vector of target values

      # Add a dummy column to accommodate the bias.
      ones = np.ones(X.shape[0])
      X = np.column_stack([ones, X])

      # Normal equation formula
      XTX = X.T.dot(X)
      XTX_inv = np.linalg.inv(XTX)
      w = XTX_inv.dot(X.T).dot(y)

      # Split the bias and the weights
      return w[0], w[1:]
#+end_src

*** Predicting the price: baseline solution

We select a few features to illustrate how things work:

#+begin_src python
  base = ['engine_hp', 'engine_cylinders', 'highway_mpg', 'city_mpg', 'popularity']
  df_num = df_train[base]
  df_num.head()
#+end_src

#+RESULTS:
:        engine_hp  engine_cylinders  highway_mpg  city_mpg  popularity
: 2735       148.0               4.0           33        24        1385
: 6720       132.0               4.0           32        25        2031
: 5878       148.0               4.0           37        28         640
: 11190       90.0               4.0           18        16         873
: 4554       385.0               8.0           21        15        5657

Replace any missing values with 0:

#+begin_src python :results silent
  df_num = df_num.fillna(0)
#+end_src

This may not be the best way to deal with missing values, but it works.

#+begin_remark
I guess what's not so great about it is that it reduces a term to zero in the
equation, causing the predicted price to be lower than one might expect. This is
the formula for predicting the price:

g(x) = w_{0} + x_{1}w_{1} + x_{2}w_{2} + x_{3}w_{3} + ...

Now if one feature is set to 0, the total sum g(x) is lower than it would have
been if the feature were not 0. A better solution might be to set unknown
features to the mean of that feature across all samples. That way the feature
still exerts its influence on the total price.

For example, if =city_mpg= is unknown, we may still assume that it isn't zero.
Setting it to zero would drive down the estimated price unreasonably. (Or drive
it up, depending on the relevant weight.)
#+end_remark

Convert the data frame to a Numpy array. This is an important step, as the
data frame cannot be fed to the function =linear_regression=:

#+begin_src python :results silent
  X_train = df_num.values
#+end_src

Now train the model:

#+begin_src python :results silent
  w_0, w = linear_regression(X_train, y_train)
#+end_src

#+begin_remark
Note: Training the model means calculating the weights (well, duh!) Here, the
weights can simply be calculated, but formally it's still training.
#+end_remark

Applying the model to the training data:

#+begin_src python :results silent
  y_pred = w_0 + X_train.dot(w)
#+end_src

And plot the result:

#+begin_src python :results file figures/figure2-04.png
  sns.histplot(y_pred, label='pred')
  sns.histplot(y_train, label='y', color='red')
  plt.legend()
  plt.savefig('figures/figure2-04.png')
  'figures/figure2-04.png'
#+end_src

#+RESULTS:
[[file:figures/figure2-04.png]]

Note: the predicted and the actual values are quite a bit apart. This is due to
the fact that the predictions here are based on only five features.

#+begin_remark
The book uses =sns.distplot()=, which however gives a deprecation warning. One
should use =sns.displot()= or =sns.histplot()= instead, but only the latter
seems to allow overlaying two plots.
#+end_remark

*** Evaluating the model: Root Mean Square Error

The Root Mean Square Error (RMSE) is a common measure for the quality of a
model:

\[
\mathrm{RMSE} = \sqrt{\frac{1}{m}\sum_{i=1}^{m}(g(x_{i})-y_{i})^{2}}
\]

RMSE in Python using Numpy:

#+begin_src python :results silent
  def rmse(y, y_pred):
      # y: array of target values
      # y_pred: array of predicted values

      error = y_pred - y
      mse = (error ** 2).mean()
      return np.sqrt(mse)
#+end_src

Note: Numpy does array operations. =y= and =y_pred= are arrays, which means that
=error= is, as well.

Computing the RMSE for the current model:

#+begin_src python
  rmse(y_train, y_pred)
#+end_src

#+RESULTS:
: 0.7554192603920132

*** Validating the model

To compare the model with other models, this measure should be computed on the
validation set, not the training set:

#+begin_src python
  # Create the matrix of validation samples X_val:
  df_num = df_val[base]
  df_num = df_num.fillna(0)
  X_val = df_num.values

  # Apply the model:
  y_pred = w_0 + X_val.dot(w)

  # Compute RMSE;
  rmse(y_val, y_pred)
#+end_src

#+RESULTS:
: 0.7616530991301577

To make this more easily repeatable:

#+begin_src python :results silent
  def prepare_X(df):
      df_num = df[base]
      df_num = df_num.fillna(0)
      X = df_num.values

      return X
#+end_src

=prepare_X= creates a matrix from a data frame. Training and evaluation are now
simpler:

#+begin_src python :results output
  X_train = prepare_X(df_train)
  w_0, w = linear_regression(X_train, y_train)

  X_val = prepare_X(df_val)
  y_pred = w_0 + X_val.dot(w)
  print('validation:', rmse(y_val, y_pred))
#+end_src

#+RESULTS:
: validation: 0.7616530991301577

*** Simple feature engineering

We can add new features based on the existing features. For example, the year a
car is produced is only a good predictor of price if it's interpreted as the age
of a car.

=df_train.year.max()= gives the newest car in the data set, which is 2017.
Subtract the year of a car from 2017 to get its age.

#+begin_src python :results silent
  def prepare_X(df):
      df = df.copy()
      features = base.copy()

      df['age'] = 2017 - df.year
      features.append('age')

      df_num = df[features]
      df_num = df_num.fillna(0)
      X = df_num.values

      return X
#+end_src

Training and evaluation can now be done as follows:

#+begin_src python :results output
  X_train = prepare_X(df_train)                    # Prepare the data.
  w_0, w = linear_regression(X_train, y_train)     # Training the model.

  X_val = prepare_X(df_val)                        # Apply the model to the validation set.
  y_pred = w_0 + X_val.dot(w)
  print('validation:', rmse(y_val, y_pred))        # Compute RMSE of the validation data
#+end_src

#+RESULTS:
: validation: 0.5172055461058327

Note: smaller values for RMSE are better, of course.

Plotting the distribution of the predicted values:

#+begin_src python :results file figures/figure2-05.png
  sns.histplot(y_pred, label='pred')
  sns.histplot(y_val, label='y', color="red")
  plt.legend()

  plt.savefig('figures/figure2-05.png')
  'figures/figure2-05.png'
#+end_src

#+RESULTS:
[[file:figures/figure2-05.png]]

*** Categorical features

Categorical features are features that take one of a limited set of values.
These are often strings, but may be numerical, as the number of doors of a car
(2, 3, or 4).

One way to handle categorical features in a model is to include a set of binary
features, one for each distinct value (called *one-hot encoding*). We can do
this in the =prepare_X= function:

#+begin_src python :results silent
  def prepare_X(df):
      # Copy the data frame and the features.
      df = df.copy()
      features = base.copy()

      # Add some features
      df['age'] = 2017 - df.year
      features.append('age')

      for v in [2, 3, 4]:
          feature = 'num_doors_%s' % v
          value = (df['number_of_doors'] == v).astype(int)
          df[feature] = value
          features.append(feature)

      # Create a new data frame with only the features and add any missing features as 0.
      df_num = df[features]
      df_num = df_num.fillna(0)

      # Extract the values into a matrix and return the result.
      X = df_num.values
      return X
#+end_src

#+begin_remark
I'm not sure when a comparison can be turned into an integer...
=True.astype(int)= returns an error, and so does =(1==0).astype(int)=, but for
some reason, =(df['number_of_doors'][0]==2).astype(int)= returns =1=.

Note that =(df['number_of_doors']==v)= is an array operation: it returns a
Pandas series of boolean values.
#+end_remark

Doing the same for the feature make, taking only the five most frequently
occurring values:

#+begin_src python :results silent
  def prepare_X(df):
      # Copy the data frame and the features.
      df = df.copy()
      features = base.copy()

      # Add some features
      df['age'] = 2017 - df.year
      features.append('age')

      for v in [2, 3, 4]:
          feature = 'num_doors_%s' % v
          value = (df['number_of_doors'] == v).astype(int)
          df[feature] = value
          features.append(feature)

      for v in ["chevrolet", "ford", "volkswagen", "toyota", "dodge"]:
          feature = 'is_make_%s' % v
          df[feature] = (df['make'] == v).astype(int)
          features.append(feature)

      # Create a new data frame with only the features and add any missing features as 0.
      df_num = df[features]
      df_num = df_num.fillna(0)

      # Extract the values into a matrix and return the result.
      X = df_num.values
      return X
#+end_src

See if it works:

#+begin_src python :results output
  X_train = prepare_X(df_train)                    # Prepare the data.
  w_0, w = linear_regression(X_train, y_train)     # Training the model.

  X_val = prepare_X(df_val)                        # Apply the model to the validation set.
  y_pred = w_0 + X_val.dot(w)
  print('validation:', rmse(y_val, y_pred))        # Compute RMSE of the validation data
#+end_src

#+RESULTS:
: validation: 0.5076038849556838

Adding some more categorical features:

#+begin_src python :results silent
  def prepare_X(df):
      # Copy the data frame and the features.
      df = df.copy()
      features = base.copy()

      # Add some features
      df['age'] = 2017 - df.year
      features.append('age')

      for v in [2, 3, 4]:
          feature = 'num_doors_%s' % v
          value = (df['number_of_doors'] == v).astype(int)
          df[feature] = value
          features.append(feature)

      for v in ["chevrolet", "ford", "volkswagen", "toyota", "dodge"]:
          feature = 'is_make_%s' % v
          df[feature] = (df['make'] == v).astype(int)
          features.append(feature)

      for v in ['regular_unleaded', 'premium_unleaded_(required)',
                'premium_unleaded_(recommended)', 'flex-fuel_(unleaded/e85)']:
          feature = 'is_type_%s' % v
          df[feature] = (df['engine_fuel_type'] == v).astype(int)
          features.append(feature)

      for v in ['automatic', 'manual', 'automated_manual']:
          feature = 'is_transmission_%s' % v
          df[feature] = (df['transmission_type'] == v).astype(int)
          features.append(feature)

      for v in ['front_wheel_drive', 'rear_wheel_drive',
                'all_wheel_drive', 'four_wheel_drive']:
          feature = 'is_driven_wheels_%s' % v
          df[feature] = (df['driven_wheels'] == v).astype(int)
          features.append(feature)

      for v in ['crossover', 'flex_fuel', 'luxury', 'luxury,performance', 'hatchback']:
          feature = 'is_mc_%s' % v
          df[feature] = (df['market_category'] == v).astype(int)
          features.append(feature)

      for v in ['compact', 'midsize', 'large']:
          feature = 'is_size_%s' % v
          df[feature] = (df['vehicle_size'] == v).astype(int)
          features.append(feature)

      for v in ['sedan', '4dr_suv', 'coupe', 'convertible', '4dr_hatchback']:
          feature = 'is_style_%s' % v
          df[feature] = (df['vehicle_style'] == v).astype(int)
          features.append(feature)

      # Create a new data frame with only the features and add any missing features as 0.
      df_num = df[features]
      df_num = df_num.fillna(0)

      # Extract the values into a matrix and return the result.
      X = df_num.values
      return X
#+end_src

Checking out the effect:

#+begin_src python :results output
  X_train = prepare_X(df_train)                    # Prepare the data.
  w_0, w = linear_regression(X_train, y_train)     # Train the model.

  X_val = prepare_X(df_val)                        # Apply the model to the validation set.
  y_pred = w_0 + X_val.dot(w)
  print('validation:', rmse(y_val, y_pred))        # Compute RMSE of the validation data
#+end_src

#+RESULTS:
: validation: 22.322123465036622

Adding these features makes the model much worse, not better.

*** Regularization

The reason for the deterioration is *numerical instability*. The bias is very
large and so are some of the weights:

#+begin_src python :results output
  print('bias: %s\nweights: %s' % (w_0, w))
#+end_src

#+RESULTS:
#+begin_example
bias: 8991164041495205.0
weights: [-4.95981777e-02  6.73670308e+00  9.40777511e-01 -2.58497309e+00
  3.72822950e-03 -5.20036150e-01 -1.40699123e+03 -1.39430142e+03
 -1.39683545e+03 -5.60490940e+00 -2.27794179e+01  1.73041774e+01
 -4.30960052e+00 -9.23053458e+00  5.11353883e+01  5.56224498e+01
  4.86289752e+01  5.76621679e+01 -2.18304488e+02 -2.07996848e+02
 -2.72177915e+02 -8.99116404e+15 -8.99116404e+15 -8.99116404e+15
 -8.99116404e+15  6.13723252e+00  6.05470595e+00 -1.21844079e+00
  3.04348851e+00  1.20577703e+00 -2.16182997e+01 -2.60265778e+01
 -2.38977036e+01 -7.67460186e-02  4.14645821e-02  1.86187511e-01
  3.55798979e-01 -2.14066472e-01]
#+end_example

The underlying cause of the problem is that the feature matrix becomes
*singular* or *undetermined*. This can happen when two features are essentially
the same, e.g., if there's a feature "miles per gallon" and you then add a
feature "kilometers per liter".

Technically, the matrix produced here is not singular, but the large bias and
weights indicate it's close.

This numerical instability can be solved using *regularization* techniques. One
way to do regularization is to add a small number to each diagonal element of
the matrix. The formula for linear regression then becomes:

w = (X^{T}·X+αI)^{-1}·X^{T}·y

I is an identity matrix, α a constant. In Numpy:

#+begin_example
  XTX = X_train.T.dot(X_train)
  XTX = XTX + 0.01 * np.eye(XTX.shape[0])
#+end_example

Here, \alpha is set to =0.01=. The function =np.eye()= creates a 2D identity matrix:

#+begin_src python
  0.01 * np.eye(4)
#+end_src

#+RESULTS:
| 0.01 |    0 |    0 |    0 |
|    0 | 0.01 |    0 |    0 |
|    0 |    0 | 0.01 |    0 |
|    0 |    0 |    0 | 0.01 |

Linear regression with regularization:

#+begin_src python :results silent
  def linear_regression_reg(X, y, r=0.01):
      ones = np.ones(X.shape[0])
      X = np.column_stack([ones, X])

      XTX = X.T.dot(X)
      reg = r * np.eye(XTX.shape[0])
      XTX = XTX + reg

      XTX_inv = np.linalg.inv(XTX)
      w = XTX_inv.dot(X.T).dot(y)

      return w[0], w[1:]
#+end_src

A grid search suggests that values around 0.01 are fine. Smaller values do
reduce the RMSE, but only marginally.

#+begin_src python :results output
  X_train = prepare_X(df_train)
  w_0, w = linear_regression_reg(X_train, y_train, r=0.01)

  X_val = prepare_X(df_val)
  y_pred = w_0 + X_val.dot(w)
  print('validation:', rmse(y_val, y_pred))

  X_test = prepare_X(df_test)
  y_pred = w_0 + X_test.dot(w)
  print('test:', rmse(y_test, y_pred))
#+end_src

#+RESULTS:
: validation: 0.46023949630840544
: test: 0.45718136795913034

The results suggest that the model works well.

#+begin_remark
Still, I'm not clear on whether the value of approx. 0.46 is good or not. Does
it mean the model predicts the price well or not?
#+end_remark

*** Using the model

When using the model to make a prediction, one needs to create a data frame with
one row. Take the following ad for a car:

#+begin_src python :results silent
  ad = {
      'city_mpg'          : 18,
      'driven_wheels'     : 'all_wheel_drive',
      'engine_cylinders'  : 6.0,
      'engine_fuel_type'  : 'regular_unleaded',
      'engine_hp'         : 268.0,
      'highway_mpg'       : 25,
      'make'              : 'toyota',
      'market_category'   : 'crossover,performance',
      'model'             : 'venza',
      'number_of_doors'   : 4.0,
      'popularity'        : 2031,
      'transmission_type' : 'automatic',
      'vehicle_size'      : 'midsize',
      'vehicle_style'     : 'wagon',
      'year'              : 2013
  }
#+end_src

Converting this to a data frame and a matrix:

#+begin_src python :results silent
  df_ad = pd.DataFrame([ad])
  X_test = prepare_X(df_ad)
#+end_src

Applying the model yields a value that is the logarithm of the predicted price.
To calculate the price, apply the exponent function:

#+begin_src python :results output
  y_pred = w_0 + X_test.dot(w)
  suggestion = np.expm1(y_pred)
  print('suggested price: $%d' % round(suggestion[0]))
#+end_src

#+RESULTS:
: suggested price: $28294


** Utility functions
:PROPERTIES:
:header-args:python+: :tangle mlutils.py :results silent :eval no
:END:

Convert the code from chapter 2 to a set of utility functions. These are tangled
to a file =mlutils.py= in the current directory, which can then be imported in
code blocks below.

#+begin_src python
  import numbers

  import pandas as pd
  import numpy as np

#+end_src

Read the data and clean up the column names / alphanumeric data:

#+begin_src python
  def read_data(file):
      """Read a dataframe from a CSV file.

      Parameters:
      file (string): path to a CSV file.

      Returns:
      DataFrame holding the contents of the file.
      """
      df = pd.read_csv(file)
      return df


  def clean_alphanum_data(df):
      """Clean up alphanumeric data in a dataframe.

      Convert all strings to lower case and replace spaces with underscores.

      Parameters:
      df (DataFrame): the dataframe to be cleaned.

      Returns:
      None.
      """
      df.columns = df.columns.str.lower().str.replace(' ', '_')

      string_columns = list(df.dtypes[df.dtypes == 'object'].index)
      for col in string_columns:
          df[col] = df[col].str.lower().str.replace(' ', '_')

#+end_src

Split the data frame into a train, validation and test set:

#+begin_src python
  def split_data_frame(df, split=0.2, seed=None, test=True):
      """Split a dataframe into a train, validation and test set.

      The dataframe is first randomized and then split into three parts. If
      `validation` is False, the dataframe is split into two parts.

      Parameters:
      df (DataFrame): the dataframe to split.
      split (float):  fraction of the dataframe to use for validation and test sets.
      seed (int):     the seed used for randomization.
      test (boolean): whether to create a test set or not.

      Returns: 3-tuple of DataFrame, DataFrame, DataFrame (train, validation,
      test). If `test` is False, the third element of the 3-tuple is None.

      """
      n = len(df)

      n_val = int(split * n)
      n_test = int(split * n) if test else 0
      n_train = n - (n_val + n_test)

      idx = np.arange(n)
      if isinstance(seed, numbers.Number):
          np.random.seed(seed)
      np.random.shuffle(idx)

      df_shuffled = df.iloc[idx]

      df_train = df_shuffled.iloc[:n_train].copy()
      df_val = df_shuffled.iloc[n_train:n_train+n_val].copy()
      df_test = df_shuffled.iloc[n_train+n_val:].copy() if test else None

      return df_train, df_val, df_test

#+end_src

Prepare the data. I add two arguments to =prepare_X=: =base=, which is a list of
the features in the dataframe that should be used, and =fns=, a list of
functions to extract additional features.

#+begin_src python
  def prepare_X(df, base, fns=[]):
      """Prepare a dataframe for learning.

      Convert the dataframe to a Numpy array:

      - Extract the features in `base`.

      - Apply the functions in `fns` to the dataframe to derive new features from
        existing ones (e.g., for binary encoding).

        The elements of `fns` should be lists `(fn, arg, arg, arg, ...)`. Before
        calling each function, `df` is prepended to the list of arguments. The
        functions should add the new features to `df`, and they should return a
        list of the names of the new feature(s) as strings.

      - Fill any missing data with 0.

      Note that `df` is not modified. The functions in `fns` should modify their
      dataframe argument, but they operate on a copy of `df`.

      Parameters:
      df (DataFrame): dataframe to convert.
      base (list of strings): list of fields in the dataframe to be used for the array.
      fns (list of tuples (function, arg list)): feature engineering functions.

      Returns:
      ndarray of the prepared data.

      """
      df = df.copy()
      features = base.copy()

      for fn, *args in fns:
          args = [df] + args
          new_features = fn(*args) # Note: `fn` should also modify the local copy of `df`!
          features += new_features

      df_num = df[features]
      df_num = df_num.fillna(0)
      X = df_num.values

      return X
#+end_src

Two functions for feature engineering:

#+begin_src python
  def binary_encode(df, feature, n=5):
      """Binary encode a categorical feature.

      Take the top `n` values of `feature` and add features to `df` to binary
      encode `feature`. The dataframe is modified in place.

      Parameters:
      df (DataFrame): the dataframe to add the feature to.
      feature (string): feature in df to be binary encoded.
      n (int): number of values for feature to encode.

      Returns:
      List of new features.

      """
      assert feature in df

      top_values = df[feature].value_counts().head(n)
      new_features = []
      for v in top_values.keys():
          binary_feature = feature + '_%s' % v
          df[binary_feature] = (df[feature] == v).astype(int)
          new_features.append(binary_feature)

      return new_features


  def encode_age(df, year_field, current_year):
      """Encode the age of an item as a feature.

      The age is calculated on the basis of the contents of `year_field` and
      `current_year`.

      Parameters:
      df (DataFrame): dataframe to encode the age in.
      year_feature (string): the feature that encodes the relevant year.
      current_year (int): the year used to calculate the age.

      Returns:
      Constant value ['age'].

      """
      assert year_field in df
      assert df[year_field].dtype == 'int64'

      df['age'] = current_year - df[year_field]

      return ['age']

#+end_src

=binary_encode= can be generalized to a function that loops over a list of
features:

#+begin_src python
  def binary_encodes(df, features, n=5):
      """Binary encode a list of features.

      Each feature is passed to `binary_encode`. See there for details. Note that
      `df` is modified in place.

      Parameters:
      df (DataFrame): the dataframe to engineer features from.
      features (list of strings): list of features to binary encode.
      n (int): number of values for feature to encode.

      Returns:
      A list of features added to `df`.

      """
      all_new_features = []
      for feature in features:
          new_features = binary_encode(df, feature, n)
          all_new_features += new_features

      return all_new_features

#+end_src

The =linear_regression= and =rmse= functions. These weren't modified:

#+begin_src python
  def linear_regression(X, y, r=0.0):
      """Perform linear regression.

      Parameters:
      X (ndarray): array of input values.
      y (ndarray): target values.
      r (float): regularization amount.

      Returns:
      Tuple of float, ndarray (bias, array of weights)

      """
      ones = np.ones(X.shape[0])
      X = np.column_stack([ones, X])

      XTX = X.T.dot(X)
      reg = r * np.eye(XTX.shape[0])
      XTX = XTX + reg

      XTX_inv = np.linalg.inv(XTX)
      w = XTX_inv.dot(X.T).dot(y)

      return w[0], w[1:]


  def rmse(y, y_pred):
      """Compute the root mean square error.

      Parameters:
      y (ndarray): target values.
      y_pred (ndarray): predicted values.

      Returns:
      float

      """
      error = y_pred - y
      mse = (error ** 2).mean()
      return np.sqrt(mse)

#+end_src


** Exercises and code
:PROPERTIES:
:header-args:python+: :session ch2-ex
:END:

*** Car prices

The goal is to see if more feature engineering improves the model. The RMSE of
the model as developed in chapter 2 is 0.46. Can this be improved?

Let us set up the model. First, read the data and clean it up:

#+begin_src python :results silent
  from mlutils import *
#+end_src

#+begin_src python
  df = read_data('../data/cars.csv')
  clean_alphanum_data(df)
  df.head()
#+end_src

#+RESULTS:
:   make       model  year             engine_fuel_type  engine_hp  engine_cylinders transmission_type  ...                        market_category  vehicle_size vehicle_style highway_mpg city_mpg  popularity   msrp
: 0  bmw  1_series_m  2011  premium_unleaded_(required)      335.0               6.0            manual  ...  factory_tuner,luxury,high-performance       compact         coupe          26       19        3916  46135
: 1  bmw    1_series  2011  premium_unleaded_(required)      300.0               6.0            manual  ...                     luxury,performance       compact   convertible          28       19        3916  40650
: 2  bmw    1_series  2011  premium_unleaded_(required)      300.0               6.0            manual  ...                luxury,high-performance       compact         coupe          28       20        3916  36350
: 3  bmw    1_series  2011  premium_unleaded_(required)      230.0               6.0            manual  ...                     luxury,performance       compact         coupe          28       18        3916  29450
: 4  bmw    1_series  2011  premium_unleaded_(required)      230.0               6.0            manual  ...                                 luxury       compact   convertible          28       18        3916  34500
:
: [5 rows x 16 columns]

Split the data set into a train, validation and test set:

#+begin_src python :results silent
  df_train, df_val, df_test = split_data_frame(df, split=0.2, seed=2)

  y_train = np.log1p(df_train.msrp.values)
  y_val = np.log1p(df_val.msrp.values)
  y_test = np.log1p(df_test.msrp.values)
#+end_src

Remove the target value ("msrp" or "manufacturer's suggested retail price") from
the data set:

#+begin_src python :results silent
  del df_train['msrp']
  del df_val['msrp']
  del df_test['msrp']
#+end_src

Prepare the data. To confirm the results in the book (and make sure my code is
working), I'll first use the same parameters:

#+begin_src python :results silent
  # Prepare the training data.
  base = ['engine_hp', 'engine_cylinders', 'highway_mpg', 'city_mpg', 'popularity']
  fns = [[encode_age, 'year', 2017],
         [binary_encodes, ["number_of_doors",
                           "make",
                           "engine_fuel_type",
                           "transmission_type",
                           "driven_wheels",
                           "market_category",
                           "vehicle_size",
                           "vehicle_style"],
          5]]
  X_train = prepare_X(df_train, base, fns)

#+end_src

Now train the model:

#+begin_src python :results silent
  w_0, w = linear_regression(X_train, y_train, 0.01)
#+end_src

If we apply the model to the training data, we *should* get the original prices
again. In reality, we don't.

#+begin_src python :results silent
  from matplotlib import pyplot as plt
  import seaborn as sns
#+end_src

#+begin_src python :results file figure/figure2-06.png
  y_pred = w_0 + X_train.dot(w)
  sns.histplot(y_pred, label='pred')
  sns.histplot(y_train, label='y', color='red')
  plt.legend()
  plt.savefig('figures/figure2-06.png')
  'figures/figure2-06.png'
#+end_src

#+RESULTS:
[[file:figures/figure2-06.png]]

We can compute the RMSE for the model:

#+begin_src python
  rmse(y_train, y_pred)
#+end_src

#+RESULTS:
: 0.46020995201980425

We should of course compute the RMSE on the validation set:

#+begin_src python
  X_val = prepare_X(df_val, base, fns)
  y_pred = w_0 + X_val.dot(w)
  rmse(y_val, y_pred)
#+end_src

#+RESULTS:
: 0.476510145790575

**** Using more values

Let's follow the suggestion in exercise 2.5.1 and include more values in the
binary encoded features:

#+begin_src python :results file figures/figure2-07.png
  base = ['engine_hp', 'engine_cylinders', 'highway_mpg', 'city_mpg', 'popularity']
  fns = [[encode_age, 'year', 2017],
         [binary_encodes, ["number_of_doors",
                           "make",
                           "engine_fuel_type",
                           "transmission_type",
                           "driven_wheels",
                           "market_category",
                           "vehicle_size",
                           "vehicle_style"],
          8]]

  X_train = prepare_X(df_train, base, fns)

  w_0, w = linear_regression(X_train, y_train, 0.01)

  y_pred = w_0 + X_train.dot(w)

  sns.histplot(y_pred, label='pred')
  sns.histplot(y_train, label='y', color='red')
  plt.legend()
  plt.savefig('figures/figure2-07.png')
  'figures/figure2-07.png'
#+end_src

#+RESULTS:
[[file:figures/figure2-07.png]]

Evaluating against the validation set:

#+begin_src python
  X_val = prepare_X(df_val, base, fns)
  y_pred = w_0 + X_val.dot(w)
  rmse(y_val, y_pred)
#+end_src

#+RESULTS:
: 0.4850113356908553

The performance seems to have degraded, not improved, although only by a little.

Note that trying to use 10 values for binary encoding fails, because the
validation set then gains an extra feature. The error reported is:

#+begin_example
  ValueError: shapes (2382,61) and (60,) not aligned: 61 (dim 1) != 60 (dim 0)
#+end_example

I assume that in the validation set, one of the features has one value more than
in the training set.

**** Differentiating more                                       :noexport:

Among the binary encoded features, some have only a few values, others have a
larger number. Cutting them all off at the same point may not be a good idea.

These are the available features, their types and their value counts:

#+begin_src python
  features = []
  for column in df.columns:
      feature = [column, df[column].dtype.name, len(df[column].value_counts())]
      print(feature)
      features.append(feature)

  features
#+end_src

#+RESULTS:
| make              | object  |   48 |
| model             | object  |  914 |
| year              | int64   |   28 |
| engine_fuel_type  | object  |   10 |
| engine_hp         | float64 |  356 |
| engine_cylinders  | float64 |    9 |
| transmission_type | object  |    5 |
| driven_wheels     | object  |    4 |
| number_of_doors   | float64 |    3 |
| market_category   | object  |   71 |
| vehicle_size      | object  |    3 |
| vehicle_style     | object  |   16 |
| highway_mpg       | int64   |   59 |
| city_mpg          | int64   |   69 |
| popularity        | int64   |   48 |
| msrp              | int64   | 6049 |

Let's check which ones were used in the model above:

| feature           | type    | n values | used |
|-------------------+---------+----------+------|
| make              | object  |       48 | *    |
| model             | object  |      914 |      |
| year              | int64   |       28 |      |
| engine_fuel_type  | object  |       10 | *    |
| engine_hp         | float64 |      356 | *    |
| engine_cylinders  | float64 |        9 | *    |
| transmission_type | object  |        5 | *    |
| driven_wheels     | object  |        4 | *    |
| number_of_doors   | float64 |        3 | *    |
| market_category   | object  |       71 | *    |
| vehicle_size      | object  |        3 | *    |
| vehicle_style     | object  |       16 | *    |
| highway_mpg       | int64   |       59 | *    |
| city_mpg          | int64   |       69 | *    |
| popularity        | int64   |       48 | *    |
| msrp              | int64   |     6049 |      |

Not sure if any of these could be engineered better. Let's get on with the next
exercise.

*** House prices

First read the data and clean it up.

#+begin_src python
  df = read_data('../data/housing.csv')
  clean_alphanum_data(df)
  df.head()
#+end_src

#+RESULTS:
:       crim    zn  indus  chas    nox     rm   age     dis  rad    tax  ptratio       b  lstat  medv
: 0  0.00632  18.0   2.31     0  0.538  6.575  65.2  4.0900    1  296.0     15.3  396.90   4.98  24.0
: 1  0.02731   0.0   7.07     0  0.469  6.421  78.9  4.9671    2  242.0     17.8  396.90   9.14  21.6
: 2  0.02729   0.0   7.07     0  0.469  7.185  61.1  4.9671    2  242.0     17.8  392.83   4.03  34.7
: 3  0.03237   0.0   2.18     0  0.458  6.998  45.8  6.0622    3  222.0     18.7  394.63   2.94  33.4
: 4  0.06905   0.0   2.18     0  0.458  7.147  54.2  6.0622    3  222.0     18.7  396.90   5.33  36.2

The header uses abbreviations:

| CRIM    | per capita crime rate by town                                         |
| ZN      | proportion of residential land zoned for lots over 25,000 sq.ft.      |
| INDUS   | proportion of non-retail business acres per town                      |
| CHAS    | Charles River dummy variable (= 1 if tract bounds river; 0 otherwise) |
| NOX     | nitric oxides concentration (parts per 10 million)                    |
| RM      | average number of rooms per dwelling                                  |
| AGE     | proportion of owner-occupied units built prior to 1940                |
| DIS     | weighted distances to five Boston employment centres                  |
| RAD     | index of accessibility to radial highways                             |
| TAX     | full-value property-tax rate per $10,000                              |
| PTRATIO | pupil-teacher ratio by town                                           |
| B       | 1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town        |
| LSTAT   | % lower status of the population                                      |
| MEDV    | Median value of owner-occupied homes in $1000’s                       |

#+begin_src python
  df.dtypes
#+end_src

#+RESULTS:
#+begin_example
crim       float64
zn         float64
indus      float64
chas         int64
nox        float64
rm         float64
age        float64
dis        float64
rad          int64
tax        float64
ptratio    float64
b          float64
lstat      float64
medv       float64
dtype: object
#+end_example

The target value is the MEDV. All values except CHAS are numeric, CHAS is
already binary, as it only contains the values 0 and 1. No preprocessing seems
to be necessary.

There are no missing values in the data set:

#+begin_src python
  df.isnull().sum()
#+end_src

#+RESULTS:
#+begin_example
crim       0
zn         0
indus      0
chas       0
nox        0
rm         0
age        0
dis        0
rad        0
tax        0
ptratio    0
b          0
lstat      0
medv       0
dtype: int64
#+end_example

Let's first plot the data:

#+begin_src python :results silent
  from matplotlib import pyplot as plt
  import seaborn as sns
#+end_src

#+begin_src python :results file figures/figure2-09.png
  sns.histplot(df.medv, kde=True)
  plt.savefig('figures/figure2-09.png')

  'figures/figure2-09.png'
#+end_src

#+RESULTS:
[[file:figures/figure2-09.png]]

Applying logarithm transformation:

#+begin_src python :results file figures/figure2-10.png
  log_price = np.log1p(df.medv)
  sns.histplot(log_price, kde=True)
  plt.savefig('figures/figure2-10.png')

  'figures/figure2-10.png'
#+end_src

#+RESULTS:
[[file:figures/figure2-10.png]]

This doesn't seem to change much. Let's try both ways and see if one comes out
better.

**** No log transformation

Since the data set isn't that big (only 506 items) and we're only playing
around, let's forego creating a test set.

#+begin_src python :results silent
  df_train, df_val, _ = split_data_frame(df, split=0.2, seed=2, test=False)

  y_train = df_train.medv.values
  y_val = df_val.medv.values

  del df_train['medv']
  del df_val['medv']
#+end_src

Prepare the training data:

#+begin_src python :results silent
  base = ['crim', 'zn', 'indus', 'chas', 'nox', 'rm', 'age', 'dis', 'rad', 'tax', 'ptratio', 'b', 'lstat']
  X_train = prepare_X(df_train, base)
#+end_src

Train the network:

#+begin_src python :results silent
  w_0, w = linear_regression(X_train, y_train, 0.01)
#+end_src

Plot the results:

#+begin_src python :results file figure/figure2-11.png
  y_pred = w_0 + X_train.dot(w)
  sns.histplot(y_pred, label='pred')
  sns.histplot(y_train, label='y', color='red')
  plt.legend()
  plt.savefig('figures/figure2-11.png')
  'figures/figure2-11.png'
#+end_src

#+RESULTS:
[[file:figures/figure2-11.png]]

Not that bad, but too high in the middle-high segment. Let's do validation:

#+begin_src python
  X_val = prepare_X(df_val, base)
  y_pred = w_0 + X_val.dot(w)
  rmse(y_val, y_pred)
#+end_src

#+RESULTS:
: 3.6761997561821307

Ugh.

**** With log transformation

Now let's apply logarithm transformation;

#+begin_src python :results silent
  df_train, df_val, _ = split_data_frame(df, split=0.2, seed=2, test=False)

  y_train = np.log1p(df_train.medv.values)
  y_val = np.log1p(df_val.medv.values)

  del df_train['medv']
  del df_val['medv']
#+end_src

Prepare the training data:

#+begin_src python :results silent
  base = ['crim', 'zn', 'indus', 'chas', 'nox', 'rm', 'age', 'dis', 'rad', 'tax', 'ptratio', 'b', 'lstat']
  X_train = prepare_X(df_train, base)
#+end_src

Train the network:

#+begin_src python :results silent
  w_0, w = linear_regression(X_train, y_train, 0.01)
#+end_src

Plot the results:

#+begin_src python :results file figure/figure2-12.png
  y_pred = w_0 + X_train.dot(w)
  sns.histplot(y_pred, label='pred')
  sns.histplot(y_train, label='y', color='red')
  plt.legend()
  plt.savefig('figures/figure2-12.png')
  'figures/figure2-12.png'
#+end_src

#+RESULTS:
[[file:figures/figure2-12.png]]

At first sight, not much better than without log transformation. But let's see:

#+begin_src python
  X_val = prepare_X(df_val, base)
  y_pred = w_0 + X_val.dot(w)
  rmse(y_val, y_pred)
#+end_src

#+RESULTS:
: 0.164499584999961

That's a much better result, it seems.


* Chapter 3: Machine Learning for Classification

** Notes to chapter 3                                             :noexport:
:PROPERTIES:
:header-args:python+: :session ch3-notes
:END:

*** Imports

#+begin_src python :results silent
  import seaborn as sns
  import pandas as pd
  from matplotlib import pyplot as plt

  from mlutils import *
#+end_src

*** Initial look at the data

#+begin_src python :results silent
  df = pd.read_csv('../data/telco-customer-churn.csv')
#+end_src

#+begin_src python
  df.head()
#+end_src

#+RESULTS:
:    customerID  gender  SeniorCitizen Partner Dependents  tenure PhoneService     MultipleLines  ... StreamingTV StreamingMovies        Contract PaperlessBilling              PaymentMethod MonthlyCharges TotalCharges Churn
: 0  7590-VHVEG  Female              0     Yes         No       1           No  No phone service  ...          No              No  Month-to-month              Yes           Electronic check          29.85        29.85    No
: 1  5575-GNVDE    Male              0      No         No      34          Yes                No  ...          No              No        One year               No               Mailed check          56.95       1889.5    No
: 2  3668-QPYBK    Male              0      No         No       2          Yes                No  ...          No              No  Month-to-month              Yes               Mailed check          53.85       108.15   Yes
: 3  7795-CFOCW    Male              0      No         No      45           No  No phone service  ...          No              No        One year               No  Bank transfer (automatic)          42.30      1840.75    No
: 4  9237-HQITU  Female              0      No         No       2          Yes                No  ...          No              No  Month-to-month              Yes           Electronic check          70.70       151.65   Yes
:
: [5 rows x 21 columns]

Transposing the table gives a better view:

#+begin_src python
  df.head().T
#+end_src

#+RESULTS:
#+begin_example
                                 0             1               2                          3                 4
customerID              7590-VHVEG    5575-GNVDE      3668-QPYBK                 7795-CFOCW        9237-HQITU
gender                      Female          Male            Male                       Male            Female
SeniorCitizen                    0             0               0                          0                 0
Partner                        Yes            No              No                         No                No
Dependents                      No            No              No                         No                No
tenure                           1            34               2                         45                 2
PhoneService                    No           Yes             Yes                         No               Yes
MultipleLines     No phone service            No              No           No phone service                No
InternetService                DSL           DSL             DSL                        DSL       Fiber optic
OnlineSecurity                  No           Yes             Yes                        Yes                No
OnlineBackup                   Yes            No             Yes                         No                No
DeviceProtection                No           Yes              No                        Yes                No
TechSupport                     No            No              No                        Yes                No
StreamingTV                     No            No              No                         No                No
StreamingMovies                 No            No              No                         No                No
Contract            Month-to-month      One year  Month-to-month                   One year    Month-to-month
PaperlessBilling               Yes            No             Yes                         No               Yes
PaymentMethod     Electronic check  Mailed check    Mailed check  Bank transfer (automatic)  Electronic check
MonthlyCharges               29.85         56.95           53.85                       42.3              70.7
TotalCharges                 29.85        1889.5          108.15                    1840.75            151.65
Churn                           No            No             Yes                         No               Yes
#+end_example

#+begin_src python
  df.dtypes
#+end_src

#+RESULTS:
#+begin_example
customerID           object
gender               object
SeniorCitizen         int64
Partner              object
Dependents           object
tenure                int64
PhoneService         object
MultipleLines        object
InternetService      object
OnlineSecurity       object
OnlineBackup         object
DeviceProtection     object
TechSupport          object
StreamingTV          object
StreamingMovies      object
Contract             object
PaperlessBilling     object
PaymentMethod        object
MonthlyCharges      float64
TotalCharges         object
Churn                object
dtype: object
#+end_example

Note that 'TotalCharges' is of type 'object', even though we'd expect it to be a
number. There are probably non-numeric characters in this field:

#+begin_src python
  total_charges = pd.to_numeric(df['TotalCharges'], errors='coerce')  # Convert to number, do not fail on errors.
  df[total_charges.isnull()][['customerID', 'TotalCharges']]          # List those where TotalCharges is empty.
#+end_src

#+RESULTS:
#+begin_example
      customerID TotalCharges
488   4472-LVYGI
753   3115-CZMZD
936   5709-LVOEQ
1082  4367-NUYAO
1340  1371-DWPAZ
3331  7644-OMVMY
3826  3213-VVOLG
4380  2520-SGTTA
5218  2923-ARZLG
6670  4075-WKNIU
6754  2775-SEFEE
#+end_example

This shows that there are some entries where "TotalCharges" contains whitespace.

#+begin_remark
This is interesting. =df[total_charges.isnull()]= produces a dataframe of those
elements in =df= where =total_charges.isnull()= is =True=. =total_charges=
itself obviously has to be a dataframe of the same number of rows as =df=. Note:
=total_charges.isnull()= produces a dataframe of one column.
#+end_remark

We simply set the missing values to 0.

#+begin_remark
Presumably, that is exactly what's intended here, since 'tenure' is 0 in all of them:
#+end_remark

#+begin_src python
  df[df.tenure == 0]
#+end_src

#+RESULTS:
#+begin_example
      customerID  gender  SeniorCitizen Partner Dependents  tenure PhoneService     MultipleLines  ...          StreamingTV      StreamingMovies  Contract PaperlessBilling              PaymentMethod MonthlyCharges TotalCharges Churn
488   4472-LVYGI  Female              0     Yes        Yes       0           No  No phone service  ...                  Yes                   No  Two year              Yes  Bank transfer (automatic)          52.55                 No
753   3115-CZMZD    Male              0      No        Yes       0          Yes                No  ...  No internet service  No internet service  Two year               No               Mailed check          20.25                 No
936   5709-LVOEQ  Female              0     Yes        Yes       0          Yes                No  ...                  Yes                  Yes  Two year               No               Mailed check          80.85                 No
1082  4367-NUYAO    Male              0     Yes        Yes       0          Yes               Yes  ...  No internet service  No internet service  Two year               No               Mailed check          25.75                 No
1340  1371-DWPAZ  Female              0     Yes        Yes       0           No  No phone service  ...                  Yes                   No  Two year               No    Credit card (automatic)          56.05                 No
3331  7644-OMVMY    Male              0     Yes        Yes       0          Yes                No  ...  No internet service  No internet service  Two year               No               Mailed check          19.85                 No
3826  3213-VVOLG    Male              0     Yes        Yes       0          Yes               Yes  ...  No internet service  No internet service  Two year               No               Mailed check          25.35                 No
4380  2520-SGTTA  Female              0     Yes        Yes       0          Yes                No  ...  No internet service  No internet service  Two year               No               Mailed check          20.00                 No
5218  2923-ARZLG    Male              0     Yes        Yes       0          Yes                No  ...  No internet service  No internet service  One year              Yes               Mailed check          19.70                 No
6670  4075-WKNIU  Female              0     Yes        Yes       0          Yes               Yes  ...                  Yes                   No  Two year               No               Mailed check          73.35                 No
6754  2775-SEFEE    Male              0      No        Yes       0          Yes               Yes  ...                   No                   No  Two year              Yes  Bank transfer (automatic)          61.90                 No

[11 rows x 21 columns]
#+end_example

#+begin_remark
Those are the same customers as above.
#+end_remark

#+begin_src python :results silent
  df.TotalCharges = pd.to_numeric(df.TotalCharges, errors='coerce')
  df.TotalCharges = df.TotalCharges.fillna(0)
#+end_src

We clean up the column names and alphanumeric data as before:

#+begin_src python :results silent
  clean_alphanum_data(df)
#+end_src

The 'churn' column has 'yes/no' as its value, but this should be 1/0:

#+begin_src python :results silent
  df.churn = (df.churn == 'yes').astype(int)
#+end_src

Instead of our own function, we use Scikit-Learn for splitting the data:

#+begin_src python :results silent
  from sklearn.model_selection import train_test_split
#+end_src

=train_test_split= only splits a dataframe into two dataframes, so in order to
get a train, test and validation set, we need to call it twice:

#+begin_src python :results silent
  df_train_full, df_test = train_test_split(df, test_size=0.2, random_state=1)
  df_train, df_val = train_test_split(df_train_full, test_size=0.2, random_state=11)

  y_train = df_train.churn.values
  y_val = df_val.churn.values

  del df_train['churn']
  del df_val['churn']
#+end_src

*** Exploratory data analysis

There are no missing values in the dataset:

#+begin_src python
  df_train_full.isnull().sum()
#+end_src

#+RESULTS:
#+begin_example
customerid          0
gender              0
seniorcitizen       0
partner             0
dependents          0
tenure              0
phoneservice        0
multiplelines       0
internetservice     0
onlinesecurity      0
onlinebackup        0
deviceprotection    0
techsupport         0
streamingtv         0
streamingmovies     0
contract            0
paperlessbilling    0
paymentmethod       0
monthlycharges      0
totalcharges        0
churn               0
dtype: int64
#+end_example

We should also check the distribution of values:

#+begin_src python
  df_train_full.churn.value_counts()
#+end_src

#+RESULTS:
: 0    4113
: 1    1521
: Name: churn, dtype: int64

We can calculate the churn rate:

\[
\mathtt{churn\_rate} = \frac{\mathtt{number\_churned}}{\mathtt{number\_not\_churned}}
\]

Or by using the =mean()= method, given that 'churn' has the value 1 for
customers that churned and 0 for customers that did not churn:

#+begin_src python
  global_mean = df_train_full.churn.mean()
  round(global_mean, 3)
#+end_src

#+RESULTS:
: 0.27

The dataset is *imbalanced*, because the proportion of churned vs. non-churned
is not 50/50.

We separate the categorical and numerical variables:

 #+begin_src python :results silent
   categorical = ['gender', 'seniorcitizen', 'partner', 'dependents',
                  'phoneservice', 'multiplelines', 'internetservice',
                  'onlinesecurity', 'onlinebackup', 'deviceprotection',
                  'techsupport', 'streamingtv', 'streamingmovies',
                  'contract', 'paperlessbilling', 'paymentmethod']
   numerical = ['tenure', 'monthlycharges', 'totalcharges']
 #+end_src

The categorical features should only have a few values:

#+begin_src python
  df_train_full[categorical].nunique()
#+end_src

#+RESULTS:
#+begin_example
gender              2
seniorcitizen       2
partner             2
dependents          2
phoneservice        2
multiplelines       3
internetservice     3
onlinesecurity      3
onlinebackup        3
deviceprotection    3
techsupport         3
streamingtv         3
streamingmovies     3
contract            3
paperlessbilling    2
paymentmethod       4
dtype: int64
#+end_example

The data is apparently clean, no preprocessing needs to be done.

*** Feature importance

*Feature importance analysis* is the process of finding out which features have
a greater influence on the target value. Numerical and categorical features
require different methods of analysis.

**** Churn rate

For categorical variables, we can check the churn rate for each variable. If it
is similar to the global churn rate, the variable is not important for the churn
rate. If the difference is larger, there is something about this variable that
sets it apart from other variables.

Take the 'gender' feature as an example:

#+begin_src python :results output
  female_mean = df_train_full[df_train_full.gender == 'female'].churn.mean()
  male_mean = df_train_full[df_train_full.gender == 'male'].churn.mean()

  print('gender == female:', round(female_mean, 3))
  print('gender == male:  ', round(male_mean, 3))
#+end_src

#+RESULTS:
: gender == female: 0.277
: gender == male:   0.263

The difference with the global churn rate are small, so gender does not have
much influence. The values for 'partner' are different:

#+begin_src python :results output
  partner_yes = df_train_full[df_train_full.partner == 'yes'].churn.mean()
  partner_no = df_train_full[df_train_full.partner == 'no'].churn.mean()

  print('partner == yes:', round(partner_yes, 3))
  print('partner == no:  ', round(partner_no, 3))
#+end_src

#+RESULTS:
: partner == yes: 0.205
: partner == no:   0.33

In this case, the difference with the global churn rate is larger, so the
variable 'partner' is useful for predicting churn.

**** Risk ratio

The *risk ratio* is the ratio of the group churn rate and the global churn rate:

\[
\mathtt{risk} = \frac{\mathtt{group\_churn}}{\mathtt{global\_churn}}
\]

For gender, the risk ratio is close to 1:

#+begin_src python :results output
  print('female risk: ', female_mean / global_mean)
  print('male risk  : ', male_mean / global_mean)
#+end_src

#+RESULTS:
: female risk:  1.0253955354648652
: male risk  :  0.9749802969838747

The risk ratio is a number between 0 and ∞. If it is close to 1, the risk of
churning in the group is similar to the risk of churning in the population as a
whole. If the risk ratio is lower than 1, the group's risk is lower than the
risk of the total population, and if the value is higher than 1, the group's
risk is higher than the risk of the total population.

#+begin_src python :results output
  print('with partner risk   : ', partner_yes / global_mean)
  print('without partner risk: ', partner_no / global_mean)
#+end_src

#+RESULTS:
: with partner risk   :  0.7594724924338315
: without partner risk:  1.2216593879412643

To do this calculation for all categorical variables, we need some code that
calculates the churn rate for all values of a variable:

#+begin_src python
  df_group = df_train_full.groupby(by='gender').churn.agg(['mean'])
  df_group['diff'] = df_group['mean'] - global_mean
  df_group['risk'] = df_group['mean'] / global_mean
  df_group
#+end_src

#+RESULTS:
:             mean      diff      risk
: gender
: female  0.276824  0.006856  1.025396
: male    0.263214 -0.006755  0.974980

#+begin_remark
This is some interesting code. The =groupby= method creates a =GroupBy= object,
in which the different values of the relevant variable are grouped, allowing
aggregate functions to be applied to them. Aggregate functions are functions
that apply over all of the elements in the group, such as =mean=, =min=, =max=,
etc. The function to apply can be supplied as a string, as done here.
#+end_remark

We can do this for all categorical features:

#+begin_src python :results output
  for col in categorical:
      df_group = df_train_full.groupby(by=col).churn.agg(['mean'])
      df_group['diff'] = df_group['mean'] - global_mean
      df_group['risk'] = df_group['mean'] / global_mean
      print(df_group)
      print('\n========================================\n')
#+end_src

#+RESULTS:
#+begin_example
            mean      diff      risk
gender
female  0.276824  0.006856  1.025396
male    0.263214 -0.006755  0.974980

========================================

                   mean      diff      risk
seniorcitizen
0              0.242270 -0.027698  0.897403
1              0.413377  0.143409  1.531208

========================================

             mean      diff      risk
partner
no       0.329809  0.059841  1.221659
yes      0.205033 -0.064935  0.759472

========================================

                mean      diff      risk
dependents
no          0.313760  0.043792  1.162212
yes         0.165666 -0.104302  0.613651

========================================

                  mean      diff      risk
phoneservice
no            0.241316 -0.028652  0.893870
yes           0.273049  0.003081  1.011412

========================================

                      mean      diff      risk
multiplelines
no                0.257407 -0.012561  0.953474
no_phone_service  0.241316 -0.028652  0.893870
yes               0.290742  0.020773  1.076948

========================================

                     mean      diff      risk
internetservice
dsl              0.192347 -0.077621  0.712482
fiber_optic      0.425171  0.155203  1.574895
no               0.077805 -0.192163  0.288201

========================================

                         mean      diff      risk
onlinesecurity
no                   0.420921  0.150953  1.559152
no_internet_service  0.077805 -0.192163  0.288201
yes                  0.153226 -0.116742  0.567570

========================================

                         mean      diff      risk
onlinebackup
no                   0.404323  0.134355  1.497672
no_internet_service  0.077805 -0.192163  0.288201
yes                  0.217232 -0.052736  0.804660

========================================

                         mean      diff      risk
deviceprotection
no                   0.395875  0.125907  1.466379
no_internet_service  0.077805 -0.192163  0.288201
yes                  0.230412 -0.039556  0.853480

========================================

                         mean      diff      risk
techsupport
no                   0.418914  0.148946  1.551717
no_internet_service  0.077805 -0.192163  0.288201
yes                  0.159926 -0.110042  0.592390

========================================

                         mean      diff      risk
streamingtv
no                   0.342832  0.072864  1.269897
no_internet_service  0.077805 -0.192163  0.288201
yes                  0.302723  0.032755  1.121328

========================================

                         mean      diff      risk
streamingmovies
no                   0.338906  0.068938  1.255358
no_internet_service  0.077805 -0.192163  0.288201
yes                  0.307273  0.037305  1.138182

========================================

                    mean      diff      risk
contract
month-to-month  0.431701  0.161733  1.599082
one_year        0.120573 -0.149395  0.446621
two_year        0.028274 -0.241694  0.104730

========================================

                      mean      diff      risk
paperlessbilling
no                0.172071 -0.097897  0.637375
yes               0.338151  0.068183  1.252560

========================================

                               mean      diff      risk
paymentmethod
bank_transfer_(automatic)  0.168171 -0.101797  0.622928
credit_card_(automatic)    0.164339 -0.105630  0.608733
electronic_check           0.455890  0.185922  1.688682
mailed_check               0.193870 -0.076098  0.718121

========================================
#+end_example

These tables tell us a lot. We see that e.g., 'gender' is not relevant for the
churn rate. Senior citizens churn more than non-seniors [or die more? JK], etc.

Looking at 'techsupport' and 'contract', we see that clients without tech
support churn more than those with tech support and that people with monthly
contracts churn more than those with one- or two-year contracts.

**** Mutual information

It is not really possible to see from this data which variable is more useful /
important for predicting churn, however. To determine this, we can measure the
degree of dependence between a categorical variable and the target value using
various metrics. For categorical variables, *mutual information* is one such
metric. Higher values of mutual information mean a higher degree of dependence.

In Scikit-Learn, mutual information can be calculated with
=mutual_info_score=:

#+begin_src python
  from sklearn.metrics import mutual_info_score

  def calculate_mi(series):
      return mutual_info_score(series, df_train_full.churn)

  df_mi = df_train_full[categorical].apply(calculate_mi)
  df_mi = df_mi.sort_values(ascending=False).to_frame(name='MI')
  df_mi
#+end_src

#+RESULTS:
#+begin_example
                        MI
contract          0.098320
onlinesecurity    0.063085
techsupport       0.061032
internetservice   0.055868
onlinebackup      0.046923
deviceprotection  0.043453
paymentmethod     0.043210
streamingtv       0.031853
streamingmovies   0.031581
paperlessbilling  0.017589
dependents        0.012346
partner           0.009968
seniorcitizen     0.009410
multiplelines     0.000857
phoneservice      0.000229
gender            0.000117
#+end_example

'contract', 'onlinesecurity' and 'techsupport' are the most important features
for predicting churn. 'gender' is very uninformative.

Note that *mutual information* only works if both variables are categorical.
Since the target value here is either 0 or 1, it is categorical. *Mutual
information* doesn't work if one of the variables is numerical, however.

**** Correlation coefficient

To estimate the importance of the three numerical variables that we have, we can
pretend the target value is numerical as well. One way to do this is to use the
*correlation coefficient*. This value indicates what one variable does if the
other changes:

- A positive correlation means that if one variable goes up, the other does, as
  well. For a binary target, this means more ones than zeros.
- A zero correlation means the variables are independent.
- A negative correlation means that if one variable goes up, the other goes down
  (or more zeros appear).

In Pandas:

#+begin_src python
  df_train_full[numerical].corrwith(df_train_full.churn)
#+end_src

#+RESULTS:
: tenure           -0.351885
: monthlycharges    0.196805
: totalcharges     -0.196353
: dtype: float64

*** Feature engineering

In Scikit-Learn, one-hot encoding of categorical features can be achieved in
various ways. We will use =DictVectorizer=. This takes a list of dictionaries
and creates a Numpy array of vectorized features. Numerical features are not
touched by this method.

First, create a dictionary from the training set:

#+begin_src python :results silent
  train_dict = df_train[categorical + numerical].to_dict('records')
#+end_src

#+begin_src python :results output
  import pprint

  pprint.pprint(train_dict[1])
#+end_src

#+RESULTS:
#+begin_example
{'contract': 'two_year',
 'dependents': 'no',
 'deviceprotection': 'yes',
 'gender': 'female',
 'internetservice': 'dsl',
 'monthlycharges': 73.5,
 'multiplelines': 'no',
 'onlinebackup': 'yes',
 'onlinesecurity': 'no',
 'paperlessbilling': 'yes',
 'partner': 'yes',
 'paymentmethod': 'credit_card_(automatic)',
 'phoneservice': 'yes',
 'seniorcitizen': 0,
 'streamingmovies': 'yes',
 'streamingtv': 'yes',
 'techsupport': 'no',
 'tenure': 26,
 'totalcharges': 1905.7}
#+end_example

The =DictVectorizer= needs to be fit to the list of dictionaries:

#+begin_src python :results silent
  from sklearn.feature_extraction import DictVectorizer

  dv = DictVectorizer(sparse=False)
  dv.fit(train_dict)
#+end_src

The =fit= method checks the list of dictionaries and figures out how many
possible values the categorical features have. Numerical features are left
alone. We can now transform the list of dictionaries:

#+begin_src python :results silent
  X_train = dv.transform(train_dict)
#+end_src

Check the result:

#+begin_src python
  X_train[1]
#+end_src

#+RESULTS:
| 0.0 | 0.0 | 1.0 | 1.0 | 0.0 | 0.0 | 0.0 | 1.0 | 1.0 | 0.0 | 1.0 | 0.0 | 0.0 | 73.5 | 1.0 | 0.0 | 0.0 | 0.0 | 0.0 | 1.0 | 1.0 | 0.0 | 0.0 | 0.0 | 1.0 | 0.0 | 1.0 | 0.0 | 1.0 | 0.0 | 0.0 | 0.0 | 1.0 | 0.0 | 0.0 | 0.0 | 1.0 | 0.0 | 0.0 | 1.0 | 1.0 | 0.0 | 0.0 | 26.0 | 1905.7 |

*** Machine learning for classification

**** Logistic regression

Logistic regression is a linear model, but despite its name it is not a
regression model, it's a classification model. In particular, it's a binary
classification model, the target value is 0 (the effect does not occur) or 1
(the effect occurs). The actual output is the probability that the effect
occurs.

A probability must be a number between 0 and 1. To ensure that the model's
output lies between 0 and 1, we use the sigmoid function. The formula for the
logistic regression function is:

\[
g(x_{i}) = S(w_{0} + x^{T}_{}_{i} w)
\]

The dot product \(x^{T}_{i} w\) can be can be unwrapped as a sum:

\[
g(x_{i}) = S(w_{0} + \sum^{n}_{j=1}^{} x_{ij}w_{j})
\]

In Python, logistic regression can be implemented similar to linear regression:

#+begin_src python :results silent
  import math

  def logistic_regression(xi):
      score = bias
      for j in range(n):
          score = score + xi[j] * w[j]
      prob = sigmoid(score)
      return prob

  def sigmoid(score):
      return 1 / (1 + math.exp(-score))
#+end_src

#+begin_remark
The code for =logistic_regression= isn't quite right. =bias= and =w= aren't
defined. The book repeats the definition of =linear_regression=, but it doesn't
conform to the definition of =linear_regression= in chapter 2.
#+end_remark

**** Training logistic regression

We need to import the module:

#+begin_src python :results silent
  from sklearn.linear_model import LogisticRegression
#+end_src

Then create a model instance and train it:

#+begin_src python :results silent
  model = LogisticRegression(solver='liblinear', random_state=1)
  model.fit(X_train, y_train)
#+end_src

Let us test the model on the validation set. First, we need to apply the same
feature engineering to the validation set:

#+begin_src python :results silent
  val_dict = df_val[categorical + numerical].to_dict('records')
  X_val = dv.transform(val_dict)
#+end_src

We can now create predictions for our validation set. The method to use is
=predict_proba=:

#+begin_src python :results silent
  y_pred = model.predict_proba(X_val)
#+end_src

Let us take a look:

#+begin_src python :results output
  print(y_pred)
#+end_src

#+RESULTS:
: [[0.77380038 0.22619962]
:  [0.77323804 0.22676196]
:  [0.72712399 0.27287601]
:  ...
:  [0.9924975  0.0075025 ]
:  [0.93711735 0.06288265]
:  [0.99569786 0.00430214]]

The result is a Numpy array of two columns: the first column contains the
probability that the target is negative (no churn in our case) and the second
contains the probability that the target is positive (churn).

The two columns convey the same information, though: the sum of the two
probabilities should always be 1. We can therefore discard one of the columns:

#+begin_src python :results silent
  y_pred = model.predict_proba(X_val)[:, 1]
#+end_src

These are so-called /soft/ predictions, because they predict the probability. In
the current case, however, we need /hard/ predictions, i.e., =True= or =False=.
We will have to set an arbitrary threshold, say 0.5:

#+begin_src python :results silent
  churn = y_pred >= 0.5
#+end_src

We now have the predictions in a form that we can use to evaluate the model. One
quality measure is *accuracy*, which can be calculated in Numpy as follows:

#+begin_src python
  (y_val == churn).mean()
#+end_src

#+RESULTS:
: 0.7923691215616682

Note that =y_val= contains values 0 and 1, while =churn= contains =True= and
=False=. They can nonetheless be compared, because Numpy casts =True= to 1 and
=False= to 0.

**** Model interpretation

The logistic regression model learns two parameters from the data:

- w_{0}: the bias.
- w = (w_{1}, w_{2}, ..., w_{n}): the weights vector.

In Scikit-Learn, w_{0} is accessible through =model.intercept_[0]=, the weights are
stored in =model.coef_[0]=.

#+begin_src python :results output
  print("bias: ", model.intercept_[0], "\nbaseline probability: ", sigmoid(model.intercept_[0]))
#+end_src

#+RESULTS:
: bias:  -0.12335101039997287
: baseline probability:  0.4692012889104188

The bias is the baseline prediction. If all other features are 0, the bias is
the predicted result. In the case of logistic regression, we would still need to
apply the sigmoid function. Here, the baseline probability is 47%, meaning that
without knowing any other features, we must assume that it is almost as likely
that a customer will churn as he is likely to stay.

The feature names are available from the =DictVectorizer= object through the
=get_feature_names= method:

#+begin_src python :results output
  pprint.pprint(dict(zip(dv.get_feature_names(), model.coef_[0].round(3))))
#+end_src

#+RESULTS:
#+begin_example
{'contract=month-to-month': 0.556,
 'contract=one_year': -0.184,
 'contract=two_year': -0.496,
 'dependents=no': -0.009,
 'dependents=yes': -0.114,
 'deviceprotection=no': 0.061,
 'deviceprotection=no_internet_service': -0.106,
 'deviceprotection=yes': -0.078,
 'gender=female': -0.043,
 'gender=male': -0.081,
 'internetservice=dsl': -0.353,
 'internetservice=fiber_optic': 0.336,
 'internetservice=no': -0.106,
 'monthlycharges': 0.001,
 'multiplelines=no': -0.17,
 'multiplelines=no_phone_service': 0.12,
 'multiplelines=yes': -0.074,
 'onlinebackup=no': 0.111,
 'onlinebackup=no_internet_service': -0.106,
 'onlinebackup=yes': -0.128,
 'onlinesecurity=no': 0.261,
 'onlinesecurity=no_internet_service': -0.106,
 'onlinesecurity=yes': -0.278,
 'paperlessbilling=no': -0.22,
 'paperlessbilling=yes': 0.096,
 'partner=no': -0.099,
 'partner=yes': -0.024,
 'paymentmethod=bank_transfer_(automatic)': -0.092,
 'paymentmethod=credit_card_(automatic)': -0.11,
 'paymentmethod=electronic_check': 0.242,
 'paymentmethod=mailed_check': -0.163,
 'phoneservice=no': 0.12,
 'phoneservice=yes': -0.244,
 'seniorcitizen': 0.258,
 'streamingmovies=no': -0.086,
 'streamingmovies=no_internet_service': -0.106,
 'streamingmovies=yes': 0.069,
 'streamingtv=no': -0.093,
 'streamingtv=no_internet_service': -0.106,
 'streamingtv=yes': 0.076,
 'techsupport=no': 0.218,
 'techsupport=no_internet_service': -0.106,
 'techsupport=yes': -0.235,
 'tenure': -0.067,
 'totalcharges': 0.0}
#+end_example

A negative weight decreases the final value and therefore reduces the
probability that the customer will churn. Positive weights raise the
probability.

**** Using the model

Let us apply the model to a customer for scoring. In order to do this, a
customer must be represented in the same way as the training data. First we put
the customer data in a dictionary:

#+begin_src python :results silent
  customer = {
      'customerid':       '8879-zkjof',
      'gender':           'female',
      'seniorcitizen':     0,
      'partner':          'no',
      'dependents':       'no',
      'tenure':            41,
      'phoneservice':     'yes',
      'multiplelines':    'no',
      'internetservice':  'dsl',
      'onlinesecurity':   'yes',
      'onlinebackup':     'no',
      'deviceprotection': 'yes',
      'techsupport':      'yes',
      'streamingtv':      'yes',
      'streamingmovies':  'yes',
      'contract':         'one_year',
      'paperlessbilling': 'yes',
      'paymentmethod':    'bank_transfer_(automatic)',
      'monthlycharges':    79.85,
      'totalcharges':      3320.75
  }
#+end_src

This dict is converted to a matrix using the =DictVectorizer=. Note that the
=DictVectorizer= object expects a list of dictionaries:

#+begin_src python :results silent
  X_test = dv.transform([customer])
#+end_src

This results in a matrix with one row:

#+begin_src python :results verbatim
  X_test
#+end_src

#+RESULTS:
: [[0.00000e+00 1.00000e+00 0.00000e+00 1.00000e+00 0.00000e+00 0.00000e+00
:   0.00000e+00 1.00000e+00 1.00000e+00 0.00000e+00 1.00000e+00 0.00000e+00
:   0.00000e+00 7.98500e+01 1.00000e+00 0.00000e+00 0.00000e+00 1.00000e+00
:   0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 1.00000e+00 0.00000e+00
:   1.00000e+00 1.00000e+00 0.00000e+00 1.00000e+00 0.00000e+00 0.00000e+00
:   0.00000e+00 0.00000e+00 1.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00
:   1.00000e+00 0.00000e+00 0.00000e+00 1.00000e+00 0.00000e+00 0.00000e+00
:   1.00000e+00 4.10000e+01 3.32075e+03]]

This can then be fed to the model to create a prediction. As with the validation
data, this yields a two-column array (with only one row), but we only need the
value from the second column:

#+begin_src python
  model.predict_proba(X_test)[0, 1]
#+end_src

#+RESULTS:
: 0.053396497111509275

The probability of this customer churning is very low.

Scoring another client:

#+begin_src python :results silent
  customer = {
      'gender':           'female',
      'seniorcitizen':     1,
      'partner':          'no',
      'dependents':       'no',
      'phoneservice':     'yes',
      'multiplelines':    'yes',
      'internetservice':  'fiber_optic',
      'onlinesecurity':   'no',
      'onlinebackup':     'no',
      'deviceprotection': 'no',
      'techsupport':      'no',
      'streamingtv':      'yes',
      'streamingmovies':  'no',
      'contract':         'month-to-month',
      'paperlessbilling': 'yes',
      'paymentmethod':    'electronic_check',
      'tenure':            1,
      'monthlycharges':    85.7,
      'totalcharges':      85.7
  }
#+end_src

#+begin_src python
  X_test = dv.transform([customer])
  model.predict_proba(X_test)[0,1]
#+end_src

#+RESULTS:
: 0.8287013608698214

This customer's probability of churning is high.


** Exercises and code

*** Lead scoring
:PROPERTIES:
:header-args:python+: :session ch3-ex1
:END:

**** Initial look at the data

The data contains the following fields:

| Variables                                        | Description                                                                                                                        |
|--------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------|
| Prospect ID                                      | A unique ID with which the customer is identified.                                                                                 |
| Lead Number                                      | A lead number assigned to each lead procured.                                                                                      |
| Lead Origin                                      | The origin identifier with which the customer was identified to be a lead. Includes API, Landing Page Submission, etc.             |
| Lead Source                                      | The source of the lead. Includes Google, Organic Search, Olark Chat, etc.                                                          |
| Do Not Email                                     | An indicator variable selected by the customer wherein they select whether of not they want to be emailed about the course or not. |
| Do Not Call                                      | An indicator variable selected by the customer wherein they select whether of not they want to be called about the course or not.  |
| Converted                                        | The target variable. Indicates whether a lead has been successfully converted or not.                                              |
| TotalVisits                                      | The total number of visits made by the customer on the website.                                                                    |
| Total Time Spent on Website                      | The total time spent by the customer on the website.                                                                               |
| Page Views Per Visit                             | Average number of pages on the website viewed during the visits.                                                                   |
| Last Activity                                    | Last activity performed by the customer. Includes Email Opened, Olark Chat Conversation, etc.                                      |
| Country                                          | The country of the customer.                                                                                                       |
| Specialization                                   | The industry domain in which the customer worked before.                                                                           |
| How did you hear about X Education               | The source from which the customer heard about X Education.                                                                        |
| What is your current occupation                  | Indicates whether the customer is a student, umemployed or employed.                                                               |
| What matters most to you in choosing this course | An option selected by the customer indicating what is their main motto behind doing this course.                                   |
| Search                                           | Indicating whether the customer had seen the ad in any of the listed items.                                                        |
| Magazine                                         |                                                                                                                                    |
| Newspaper Article                                |                                                                                                                                    |
| X Education Forums                               |                                                                                                                                    |
| Newspaper                                        |                                                                                                                                    |
| Digital Advertisement                            |                                                                                                                                    |
| Through Recommendations                          | Indicates whether the customer came in through recommendations.                                                                    |
| Receive More Updates About Our Courses           | Indicates whether the customer chose to receive more updates about the courses.                                                    |
| Tags                                             | Tags assigned to customers indicating the current status of the lead.                                                              |
| Lead Quality                                     | Indicates the quality of lead based on the data and intuition the the employee who has been assigned to the lead.                  |
| Update me on Supply Chain Content                | Indicates whether the customer wants updates on the Supply Chain Content.                                                          |
| Get updates on DM Content                        | Indicates whether the customer wants updates on the DM Content.                                                                    |
| Lead Profile                                     | A lead level assigned to each customer based on their profile.                                                                     |
| City                                             | The city of the customer.                                                                                                          |
| Asymmetrique Activity Index                      | An index and score assigned to each customer based on their activity and their profile                                             |
| Asymmetrique Profile Index                       |                                                                                                                                    |
| Asymmetrique Activity Score                      |                                                                                                                                    |
| Asymmetrique Profile Score                       |                                                                                                                                    |
| I agree to pay the amount through cheque         | Indicates whether the customer has agreed to pay the amount through cheque or not.                                                 |
| a free copy of Mastering The Interview           | Indicates whether the customer wants a free copy of 'Mastering the Interview' or not.                                              |
| Last Notable Activity                            | The last notable acitivity performed by the student.                                                                               |

Note: The field "Specialization" includes the level 'Select Specialization'
which means the customer has not selected this option while filling the form.

**** Imports

#+begin_src python :results silent
  from mlutils import *

  import numpy as np
  import pandas as pd
#+end_src

**** Read the data:

#+begin_src python :results silent
  df = pd.read_csv('../data/Leads.csv')
#+end_src

#+begin_src python
  df.head(4).T
#+end_src

#+RESULTS:
#+begin_example
                                                                                  0                                     1                                     2                                     3
Prospect ID                                    7927b2df-8bba-4d29-b9a2-b6e0beafe620  2a272436-5132-4136-86fa-dcc88c88f482  8cc8c611-a219-4f35-ad23-fdfd2656bd8a  0cc2df48-7cf4-4e39-9de9-19797f9b38cc
Lead Number                                                                  660737                                660728                                660727                                660719
Lead Origin                                                                     API                                   API               Landing Page Submission               Landing Page Submission
Lead Source                                                              Olark Chat                        Organic Search                        Direct Traffic                        Direct Traffic
Do Not Email                                                                     No                                    No                                    No                                    No
Do Not Call                                                                      No                                    No                                    No                                    No
Converted                                                                         0                                     0                                     1                                     0
TotalVisits                                                                       0                                     5                                     2                                     1
Total Time Spent on Website                                                       0                                   674                                  1532                                   305
Page Views Per Visit                                                              0                                   2.5                                     2                                     1
Last Activity                                               Page Visited on Website                          Email Opened                          Email Opened                           Unreachable
Country                                                                         NaN                                 India                                 India                                 India
Specialization                                                               Select                                Select               Business Administration                 Media and Advertising
How did you hear about X Education                                           Select                                Select                                Select                         Word Of Mouth
What is your current occupation                                          Unemployed                            Unemployed                               Student                            Unemployed
What matters most to you in choosing a course               Better Career Prospects               Better Career Prospects               Better Career Prospects               Better Career Prospects
Search                                                                           No                                    No                                    No                                    No
Magazine                                                                         No                                    No                                    No                                    No
Newspaper Article                                                                No                                    No                                    No                                    No
X Education Forums                                                               No                                    No                                    No                                    No
Newspaper                                                                        No                                    No                                    No                                    No
Digital Advertisement                                                            No                                    No                                    No                                    No
Through Recommendations                                                          No                                    No                                    No                                    No
Receive More Updates About Our Courses                                           No                                    No                                    No                                    No
Tags                                                    Interested in other courses                               Ringing   Will revert after reading the email                               Ringing
Lead Quality                                                       Low in Relevance                                   NaN                              Might be                              Not Sure
Update me on Supply Chain Content                                                No                                    No                                    No                                    No
Get updates on DM Content                                                        No                                    No                                    No                                    No
Lead Profile                                                                 Select                                Select                        Potential Lead                                Select
City                                                                         Select                                Select                                Mumbai                                Mumbai
Asymmetrique Activity Index                                               02.Medium                             02.Medium                             02.Medium                             02.Medium
Asymmetrique Profile Index                                                02.Medium                             02.Medium                               01.High                               01.High
Asymmetrique Activity Score                                                      15                                    15                                    14                                    13
Asymmetrique Profile Score                                                       15                                    15                                    20                                    17
I agree to pay the amount through cheque                                         No                                    No                                    No                                    No
A free copy of Mastering The Interview                                           No                                    No                                   Yes                                    No
Last Notable Activity                                                      Modified                          Email Opened                          Email Opened                              Modified
#+end_example

**** Normalise alphanumeric data:

#+begin_src python :results silent
  clean_alphanum_data(df)
#+end_src

**** Variable types

The types of the variables:

#+begin_src python
  df.dtypes
#+end_src

#+RESULTS:
#+begin_example
prospect_id                                       object
lead_number                                        int64
lead_origin                                       object
lead_source                                       object
do_not_email                                      object
do_not_call                                       object
converted                                          int64
totalvisits                                      float64
total_time_spent_on_website                        int64
page_views_per_visit                             float64
last_activity                                     object
country                                           object
specialization                                    object
how_did_you_hear_about_x_education                object
what_is_your_current_occupation                   object
what_matters_most_to_you_in_choosing_a_course     object
search                                            object
magazine                                          object
newspaper_article                                 object
x_education_forums                                object
newspaper                                         object
digital_advertisement                             object
through_recommendations                           object
receive_more_updates_about_our_courses            object
tags                                              object
lead_quality                                      object
update_me_on_supply_chain_content                 object
get_updates_on_dm_content                         object
lead_profile                                      object
city                                              object
asymmetrique_activity_index                       object
asymmetrique_profile_index                        object
asymmetrique_activity_score                      float64
asymmetrique_profile_score                       float64
i_agree_to_pay_the_amount_through_cheque          object
a_free_copy_of_mastering_the_interview            object
last_notable_activity                             object
dtype: object
#+end_example

**** Check the target value:

The target variable is 'Converted', which is numerical. Let's see if it's
binary:

#+begin_src python
  df.converted.value_counts()
#+end_src

#+RESULTS:
: 0    5679
: 1    3561
: Name: converted, dtype: int64

The dataset is imbalanced:

#+begin_src python
  global_mean = df.converted.mean()
  round(global_mean, 3)
#+end_src

#+RESULTS:
: 0.385

**** Handling empty data:

#+begin_src python
  df.isnull().sum()
#+end_src

#+RESULTS:
#+begin_example
prospect_id                                         0
lead_number                                         0
lead_origin                                         0
lead_source                                        36
do_not_email                                        0
do_not_call                                         0
converted                                           0
totalvisits                                       137
total_time_spent_on_website                         0
page_views_per_visit                              137
last_activity                                     103
country                                          2461
specialization                                   1438
how_did_you_hear_about_x_education               2207
what_is_your_current_occupation                  2690
what_matters_most_to_you_in_choosing_a_course    2709
search                                              0
magazine                                            0
newspaper_article                                   0
x_education_forums                                  0
newspaper                                           0
digital_advertisement                               0
through_recommendations                             0
receive_more_updates_about_our_courses              0
tags                                             3353
lead_quality                                     4767
update_me_on_supply_chain_content                   0
get_updates_on_dm_content                           0
lead_profile                                     2709
city                                             1420
asymmetrique_activity_index                      4218
asymmetrique_profile_index                       4218
asymmetrique_activity_score                      4218
asymmetrique_profile_score                       4218
i_agree_to_pay_the_amount_through_cheque            0
a_free_copy_of_mastering_the_interview              0
last_notable_activity                               0
dtype: int64
#+end_example

| Feature                                       | type    | missing values |
|-----------------------------------------------+---------+----------------|
| prospect_id                                   | object  |              0 |
| lead_number                                   | int64   |              0 |
| lead_origin                                   | object  |              0 |
| lead_source                                   | object  |             36 |
| do_not_email                                  | object  |              0 |
| do_not_call                                   | object  |              0 |
| converted                                     | int64   |              0 |
| totalvisits                                   | float64 |            137 |
| total_time_spent_on_website                   | int64   |              0 |
| page_views_per_visit                          | float64 |            137 |
| last_activity                                 | object  |            103 |
| country                                       | object  |           2461 |
| specialization                                | object  |           1438 |
| how_did_you_hear_about_x_education            | object  |           2207 |
| what_is_your_current_occupation               | object  |           2690 |
| what_matters_most_to_you_in_choosing_a_course | object  |           2709 |
| search                                        | object  |              0 |
| magazine                                      | object  |              0 |
| newspaper_article                             | object  |              0 |
| x_education_forums                            | object  |              0 |
| newspaper                                     | object  |              0 |
| digital_advertisement                         | object  |              0 |
| through_recommendations                       | object  |              0 |
| receive_more_updates_about_our_courses        | object  |              0 |
| tags                                          | object  |           3353 |
| lead_quality                                  | object  |           4767 |
| update_me_on_supply_chain_content             | object  |              0 |
| get_updates_on_dm_content                     | object  |              0 |
| lead_profile                                  | object  |           2709 |
| city                                          | object  |           1420 |
| asymmetrique_activity_index                   | object  |           4218 |
| asymmetrique_profile_index                    | object  |           4218 |
| asymmetrique_activity_score                   | float64 |           4218 |
| asymmetrique_profile_score                    | float64 |           4218 |
| i_agree_to_pay_the_amount_through_cheque      | object  |              0 |
| a_free_copy_of_mastering_the_interview        | object  |              0 |
| last_notable_activity                         | object  |              0 |

Let's get lists of numerical and categorical features:

#+begin_src python :results silent
  numerical, categorical = [], []

  for e in zip(df.columns, df.dtypes):
      if e[1] == np.object:
          categorical.append(e[0])
      else:
          numerical.append(e[0])

  # The target value is still part of the list, so we remove it:
  numerical.remove('converted')
#+end_src

Check item 77, which has some missing values:

#+begin_src python
  df.iloc[77]
#+end_src

#+RESULTS:
#+begin_example
prospect_id                                      895d4905-f534-4f18-915b-8d239a72b5dc
lead_number                                                                    659722
lead_origin                                                             lead_add_form
lead_source                                                          welingak_website
do_not_email                                                                       no
do_not_call                                                                        no
converted                                                                           1
totalvisits                                                                       NaN
total_time_spent_on_website                                                      1096
page_views_per_visit                                                              NaN
last_activity                                                                     NaN
country                                                                           NaN
specialization                                                                 select
how_did_you_hear_about_x_education                                             select
what_is_your_current_occupation                                            unemployed
what_matters_most_to_you_in_choosing_a_course                 better_career_prospects
search                                                                             no
magazine                                                                           no
newspaper_article                                                                  no
x_education_forums                                                                 no
newspaper                                                                          no
digital_advertisement                                                              no
through_recommendations                                                            no
receive_more_updates_about_our_courses                                             no
tags                                                                              NaN
lead_quality                                                                      NaN
update_me_on_supply_chain_content                                                  no
get_updates_on_dm_content                                                          no
lead_profile                                                                   select
city                                                                           select
asymmetrique_activity_index                                                 02.medium
asymmetrique_profile_index                                                  02.medium
asymmetrique_activity_score                                                        14
asymmetrique_profile_score                                                         15
i_agree_to_pay_the_amount_through_cheque                                           no
a_free_copy_of_mastering_the_interview                                             no
last_notable_activity                                                        modified
Name: 77, dtype: object
#+end_example

Set missing numerical values to 0 and missing categorical values to 'n.a.':

#+begin_src python :results silent
  df[numerical] = df[numerical].fillna(0)
  df[categorical] = df[categorical].fillna('n.a.')
#+end_src

See if it worked:

#+begin_src python
  df.iloc[77]
#+end_src

#+RESULTS:
#+begin_example
prospect_id                                      895d4905-f534-4f18-915b-8d239a72b5dc
lead_number                                                                    659722
lead_origin                                                             lead_add_form
lead_source                                                          welingak_website
do_not_email                                                                       no
do_not_call                                                                        no
converted                                                                           1
totalvisits                                                                         0
total_time_spent_on_website                                                      1096
page_views_per_visit                                                                0
last_activity                                                                    n.a.
country                                                                          n.a.
specialization                                                                 select
how_did_you_hear_about_x_education                                             select
what_is_your_current_occupation                                            unemployed
what_matters_most_to_you_in_choosing_a_course                 better_career_prospects
search                                                                             no
magazine                                                                           no
newspaper_article                                                                  no
x_education_forums                                                                 no
newspaper                                                                          no
digital_advertisement                                                              no
through_recommendations                                                            no
receive_more_updates_about_our_courses                                             no
tags                                                                             n.a.
lead_quality                                                                     n.a.
update_me_on_supply_chain_content                                                  no
get_updates_on_dm_content                                                          no
lead_profile                                                                   select
city                                                                           select
asymmetrique_activity_index                                                 02.medium
asymmetrique_profile_index                                                  02.medium
asymmetrique_activity_score                                                        14
asymmetrique_profile_score                                                         15
i_agree_to_pay_the_amount_through_cheque                                           no
a_free_copy_of_mastering_the_interview                                             no
last_notable_activity                                                        modified
Name: 77, dtype: object
#+end_example

Yes, it worked.

**** Splitting the data:

#+begin_src python :results silent
  from sklearn.model_selection import train_test_split

  df_train_full, df_test = train_test_split(df, test_size=0.2, random_state=1)
  df_train, df_val = train_test_split(df_train_full, test_size=0.2, random_state=11)

  y_train = df_train.converted.values
  y_val = df_val.converted.values

  del df_train['converted']
  del df_val['converted']
#+end_src

**** Assessing feature importance

There are quite a few features, some categorical features have quite a few
values:

#+begin_src python
  df[categorical].nunique()
#+end_src

#+RESULTS:
#+begin_example
prospect_id                                      9240
lead_origin                                         5
lead_source                                        21
do_not_email                                        2
do_not_call                                         2
last_activity                                      18
country                                            39
specialization                                     20
how_did_you_hear_about_x_education                 11
what_is_your_current_occupation                     7
what_matters_most_to_you_in_choosing_a_course       4
search                                              2
magazine                                            1
newspaper_article                                   2
x_education_forums                                  2
newspaper                                           2
digital_advertisement                               2
through_recommendations                             2
receive_more_updates_about_our_courses              1
tags                                               27
lead_quality                                        6
update_me_on_supply_chain_content                   1
get_updates_on_dm_content                           1
lead_profile                                        7
city                                                8
asymmetrique_activity_index                         4
asymmetrique_profile_index                          4
i_agree_to_pay_the_amount_through_cheque            1
a_free_copy_of_mastering_the_interview              2
last_notable_activity                              16
dtype: int64
#+end_example

=prospect_id= should of course be removed:

#+begin_src python :results silent
  categorical.remove('prospect_id')
#+end_src

#+begin_src python
  from sklearn.metrics import mutual_info_score

  def calculate_mi(series):
      return mutual_info_score(series, df_train_full.converted)

  df_mi = df_train_full[categorical].apply(calculate_mi)
  df_mi = df_mi.sort_values(ascending=False).to_frame(name='MI')
  df_mi
#+end_src

#+RESULTS:
#+begin_example
                                                         MI
tags                                           3.769913e-01
lead_quality                                   1.861223e-01
lead_profile                                   1.138871e-01
what_is_your_current_occupation                9.238140e-02
last_activity                                  8.853869e-02
last_notable_activity                          7.251663e-02
lead_source                                    6.245069e-02
what_matters_most_to_you_in_choosing_a_course  5.569131e-02
lead_origin                                    5.559875e-02
how_did_you_hear_about_x_education             4.773990e-02
specialization                                 3.784505e-02
city                                           3.601412e-02
asymmetrique_activity_index                    1.161577e-02
asymmetrique_profile_index                     8.982885e-03
do_not_email                                   8.910986e-03
country                                        4.992103e-03
a_free_copy_of_mastering_the_interview         7.452385e-04
through_recommendations                        1.505137e-04
digital_advertisement                          1.307250e-04
do_not_call                                    1.298057e-04
newspaper_article                              1.298057e-04
newspaper                                      6.535683e-05
search                                         1.204580e-06
get_updates_on_dm_content                      7.771561e-16
magazine                                       7.771561e-16
x_education_forums                             7.771561e-16
receive_more_updates_about_our_courses         7.771561e-16
i_agree_to_pay_the_amount_through_cheque       7.771561e-16
update_me_on_supply_chain_content              7.771561e-16
#+end_example

So let's make a fairly arbitrary choice and take the first 13 features:

#+begin_src python :results silent
  categorical_included = ['tags',
                          'lead_quality',
                          'lead_profile',
                          'what_is_your_current_occupation',
                          'last_activity',
                          'last_notable_activity',
                          'lead_source',
                          'what_matters_most_to_you_in_choosing_a_course',
                          'lead_origin',
                          'how_did_you_hear_about_x_education',
                          'specialization',
                          'city',
                          'asymmetrique_activity_index']
#+end_src

Check the numerical features:

#+begin_src python
  df_train_full[numerical].corrwith(df_train_full.converted)
#+end_src

#+RESULTS:
: lead_number                    0.021904
: totalvisits                    0.026085
: total_time_spent_on_website    0.363470
: page_views_per_visit          -0.009781
: asymmetrique_activity_score    0.018662
: asymmetrique_profile_score     0.027745
: dtype: float64

Let's just include them all:

#+begin_src python :results silent
  numerical_included = numerical
#+end_src

**** Creating a vectorizer:

First try with all features:

#+begin_src python :results silent
  from sklearn.feature_extraction import DictVectorizer

  train_dict = df_train[numerical + categorical].to_dict('records')
  dv = DictVectorizer(sparse=False)
  dv.fit(train_dict)
#+end_src

Create the training set:

#+begin_src python :results silent
  X_train = dv.transform(train_dict)
#+end_src

**** Training the model:

#+begin_src python :results silent
  from sklearn.linear_model import LogisticRegression

  model = LogisticRegression(solver='liblinear', random_state=1)
  model.fit(X_train, y_train)
#+end_src

**** Evaluating the model

Let's first check against the target values, using 0.5 as the cut-off point for
a prediction of =True=. This is still with all the features.

#+begin_src python
  y_pred = model.predict_proba(X_train)[:,1]
  conversion = y_pred >= 0.5
  (conversion == y_train).mean()
#+end_src

#+RESULTS:
: 0.7226450194486724

Now check the validation set:

#+begin_src python
  val_dict = df_val[numerical + categorical].to_dict('records')
  X_val = dv.transform(val_dict)
  y_val_pred = model.predict_proba(X_val)[:,1]
  conversion = y_val_pred >= 0.5
  round((conversion == y_val).mean(), 3)
#+end_src

#+RESULTS:
: 0.72

The performance on the validation set is the same as the performance on the
training set.

**** Try with fewer features:

We create a new vectorizer with only the features that we selected above.

#+begin_src python :results output
  train_dict = df_train[numerical_included + categorical_included].to_dict('records')
  val_dict = df_val[numerical_included + categorical_included].to_dict('records')
  v = DictVectorizer(sparse=False)
  dv.fit(train_dict)

  X_train = dv.transform(train_dict)
  X_val = dv.transform(val_dict)

  model = LogisticRegression(solver='liblinear', random_state=1)
  model.fit(X_train, y_train)

  y_pred = model.predict_proba(X_train)[:,1]
  y_pred_val = model.predict_proba(X_val)[:,1]

  conversion_train = y_pred >= 0.5
  accuracy_train = (conversion_train == y_train).mean()

  conversion_val = y_pred_val >= 0.5
  accuracy_val = (conversion_val == y_val).mean()

  print('training set accuracy  :', round(accuracy_train, 3))
  print('validation set accuracy:', round(accuracy_val, 3))
#+end_src

#+RESULTS:
: training set accuracy  : 0.723
: validation set accuracy: 0.72

Apparently, removing features with little importance has little effect on the
model's performance.

Let's try again with yet fewer features:

#+begin_src python :results silent
  categorical_included = ['tags',
                          'lead_quality',
                          'lead_profile',
                          'what_is_your_current_occupation',
                          'last_activity',
                          'last_notable_activity']
#+end_src

#+begin_src python :results output
  train_dict = df_train[numerical_included + categorical_included].to_dict('records')
  val_dict = df_val[numerical_included + categorical_included].to_dict('records')
  v = DictVectorizer(sparse=False)
  dv.fit(train_dict)

  X_train = dv.transform(train_dict)
  X_val = dv.transform(val_dict)

  model = LogisticRegression(solver='liblinear', random_state=1)
  model.fit(X_train, y_train)

  y_pred = model.predict_proba(X_train)[:,1]
  y_pred_val = model.predict_proba(X_val)[:,1]

  conversion_train = y_pred >= 0.5
  accuracy_train = (conversion_train == y_train).mean()

  conversion_val = y_pred_val >= 0.5
  accuracy_val = (conversion_val == y_val).mean()

  print('training set accuracy  :', round(accuracy_train, 3))
  print('validation set accuracy:', round(accuracy_val, 3))
#+end_src

#+RESULTS:
: training set accuracy  : 0.723
: validation set accuracy: 0.72

Nope, still doesn't seem to do any better.

*** Default prediction
:PROPERTIES:
:header-args:python+: :session ch3-ex2
:END:


* Chapter 4: Evaluation metrics for classification
:PROPERTIES:
:header-args:jupyter-python+: :session mlbc4 :kernel mlbc-3mO1CerA-py3.9
:END:

** Notes to chapter 4                                             :noexport:

*** Repeat the code from chapter 3

#+NAME: src:ch4-setup-code
#+begin_src jupyter-python :results silent
  import numpy as np
  import pandas as pd

  from sklearn.model_selection import train_test_split
  from sklearn.feature_extraction import DictVectorizer
  from sklearn.linear_model import LogisticRegression

  from matplotlib import pyplot as plt

  from mlutils import clean_alphanum_data

  df = pd.read_csv('../data/telco-customer-churn.csv')

  clean_alphanum_data(df)

  df.churn = (df.churn == 'yes').astype(int)

  df_train_full, df_test = train_test_split(df, test_size=0.2, random_state=1)
  df_train, df_val = train_test_split(df_train_full, test_size=0.2, random_state=11)

  y_train = df_train.churn.values
  y_val = df_val.churn.values

  del df_train['churn']
  del df_val['churn']

  categorical = ['gender', 'seniorcitizen', 'partner', 'dependents',
                 'phoneservice', 'multiplelines', 'internetservice',
                 'onlinesecurity', 'onlinebackup', 'deviceprotection',
                 'techsupport', 'streamingtv', 'streamingmovies',
                 'contract', 'paperlessbilling', 'paymentmethod']
  numerical = ['tenure', 'monthlycharges', 'totalcharges']

  train_dict = df_train[categorical + numerical].to_dict('records')

  dv = DictVectorizer(sparse=False)
  dv.fit(train_dict)

  X_train = dv.transform(train_dict)

  model = LogisticRegression(solver='liblinear', random_state=1)
  model.fit(X_train, y_train)

  val_dict = df_val[categorical + numerical].to_dict('records')
  X_val = dv.transform(val_dict)
#+end_src

*** Classification accuracy

Calculate the accuracy:

#+begin_src jupyter-python
  y_pred = model.predict_proba(X_val)[:,1]
  churn = y_pred >= 0.5
  round((churn == y_val).mean(), 3)
#+end_src

#+RESULTS:
: 0.795

Scikit-learn also offers various metrics to evaluate a model:

#+begin_src jupyter-python :results silent
  from sklearn.metrics import accuracy_score
#+end_src

Now let's loop over several threshold values to see which one gives the best accuracy:

#+begin_src jupyter-python :results output
  thresholds = np.linspace(0, 1, 11)

  for t in thresholds:
      churn = y_pred >= t
      acc = accuracy_score(y_val, churn)
      print('%0.1f %0.3f' % (t, acc))
#+end_src

#+RESULTS:
#+begin_example
  0.0 0.264
  0.1 0.585
  0.2 0.685
  0.3 0.745
  0.4 0.775
  0.5 0.795
  0.6 0.789
  0.7 0.776
  0.8 0.749
  0.9 0.736
  1.0 0.736
#+end_example

A threshold value of 0.5 gives the best accuracy.

*** Dummy baseline

The best our model can do is an 80% accuracy. The question is whether this is
actually a *good* score. In order to assess this, we must compare the score with
something else, a baseline model. One option is to use a dummy baseline: a model
that always predicts the same value.

Since most users do not churn, such a dummy baseline would predict =False= for
all users. This is easy to set up:

#+begin_src jupyter-python :results silent
  size_val = len(y_val)
  baseline = np.repeat(False, size_val)
#+end_src

This simply creates an array of the same size as =y_val= with all =False=
values. The accuracy of such a prediction against =y_val= is:

#+begin_src jupyter-python :results output
  print(f"Accuracy: {round(accuracy_score(baseline, y_val), 3)}")
#+end_src

#+RESULTS:
: Accuracy: 0.736

The baseline accuracy isn't that much worse than what our model predicts, so
from the looks of it, our model isn't all that good.

Still, predicting churn could be a very hard problem and a 6 percentage points
increase may actually be quite a lot. We need other metrics to determine that.

*** Confusion table

A seemingly high accuracy (80%) vs. a baseline that's almost as good (74%) is
common for imbalanced datasets. A better metric would be a *confusion table*: a
table that concisely represents every possible outcome for our model’s
predictions.

A confusion table lists the true and false positives (TP / NP) and the true and
false negatives (TN / FN):

+----------------+---------------+
|                |  Predictions  |
|                |               |
|                +-------+-------+
|                | False | True  |
+--------+-------+-------+-------+
|        | False |  TN   |  FP   |
| Actual +-------+-------+-------+
|        | True  |  FN   |  TP   |
+--------+-------+-------+-------+

If we substitute the actual numbers, we get the confusion table:

+----------------+---------------+
|                |  Predictions  |
|                |               |
|                +-------+-------+
|                | False | True  |
+--------+-------+-------+-------+
|        | False | 1202  |  172  |
| Actual +-------+-------+-------+
|        | True  |  197  |  289  |
+--------+-------+-------+-------+

We can easily do this in Numpy:

#+begin_src jupyter-python :results silent
  t = 0.5
  predict_churn = (y_pred >= t)
  predict_no_churn = (y_pred < t)

  actual_churn = (y_val == 1)
  actual_no_churn = (y_val == 0)

  true_positive = (predict_churn & actual_churn).sum()
  false_positive = (predict_churn & actual_no_churn).sum()

  false_negative = (predict_no_churn & actual_churn).sum()
  true_negative = (predict_no_churn & actual_no_churn).sum()

  confusion_table = np.array(
      [[true_negative, false_positive],
       [false_negative, true_positive]])

  confusion_table = confusion_table / confusion_table.sum()
#+end_src

Since we only have 0 and 1 in the lists of true/false positives and negatives,
summing them gives the number of items in them. Summing the confusion table
itself gives the total number of items.

#+begin_src jupyter-python
  confusion_table.round(3)
#+end_src

#+RESULTS:
: array([[0.645, 0.091],
:        [0.114, 0.15 ]])

Let us plug these values into the table above, for a better overview:

+----------------+---------------+
|                |  Predictions  |
|                |               |
|                +-------+-------+
|                | False | True  |
+--------+-------+-------+-------+
|        | False | 0.645 | 0.091 |
| Actual +-------+-------+-------+
|        | True  | 0.114 | 0.15  |
+--------+-------+-------+-------+

The model is fairly good at predicting non-churning (65% of predictions are true
negatives), but there are quite a few mistakes of both types (9% and 11%).

#+begin_remark
Note that 65% here does not mean that 65% percent of non-churners are predicted
correctly. It means that of the predictions made, 65% are true negatives. The
percentage of non-churners is 65+9=74%; of these, 65/74*100=87.8% were predicted
correctly.

Similarly, the percentage of churners is 11+15=26%; of these 15/26*100=60% were
predicted correctly.
#+end_remark

We can calculate an accuracy score for the model based on these numbers in the
following way:

accuracy = (TN + TP) / (TN + TP + FN + FP)

which gives us:

#+begin_src jupyter-python :results output
  accuracy = (true_negative + true_positive) / (true_negative + true_positive + false_negative + false_positive)
  print(f"Accuracy: {round(accuracy, 2)}")
#+end_src

#+RESULTS:
: Accuracy: 0.8

*** Precision and recall

Accuracy is not a very good metric for imbalanced datasets. Instead, one can use
*precision* and *recall*, which are both calculated from the confusion table.

*Precision* is the fraction of the true positives in relation of all positive
predictions:

P = TP / (TP + FP)

In our case:

#+begin_src jupyter-python :results output
  print(f"Precision: {round(true_positive / (true_positive + false_positive), 2)}")
#+end_src

#+RESULTS:
: Precision: 0.62

*Recall* is the fraction of true positives in relation to all positives:

R = TP / (TP + FN)

In our case:

#+begin_src jupyter-python :results output
  print(f"Recall: {round(true_positive / (true_positive + false_negative), 2)}")
#+end_src

#+RESULTS:
: Recall: 0.57

Neither precision nor recall take true negatives into account. In imbalanced
datasets, these are usually the largest group (in our case, they constitute 64.5%
of all predictions), but at the same time, they are usually not very
interesting.

The reason for this is that we are trying to predict who is going to churn. We
may make two kinds of mistakes:

- Predict someone is going to churn when they weren't; these are false positives.
- Fail to predict someone who is going to churn; these are false negatives.

These are the two errors that precision and recall help us quantify. True
negatives are not interesting to us because we weren't going to do anything with
them anyway.

While 80% accuracy may seem quite good, precision and recall tell us that the
model makes quite a few mistakes. This is not necessarily a deal breaker, as
errors are expected. At least we have a better idea of how the model performs.

*** ROC curve and AUC score

Precision and recall can only assess a model at one particular threshold. ROC
curve and AUC score are metrics that can be used to assess a model across all
possible threshold values.

**** ROC curve

ROC stands for "receiver operating characteristics"; it's a metric designed to
asses how well a detector can separate two signals: True and False. For this we
need two metrics: *true positive rate (TPR)* and *false positive rate (FPR)*:

- FPR: fraction of false positives among all negative examples.
- TPR: fraction of true positives among all positive examples.

They can be calculated on the basis of the confusion table:

FPR = FP / (FP + TN)

TPR = TP / (TP + FN)

FPR involves the first row of the table, TPR involves the second row.

For our model, these values are:

FPR = 172 / 1374 = 12.5%

TPR = 289 / 486 = 59%

#+begin_remark
Note, these values are taken directly from the book. In our model, they might
vary slightly.
#+end_remark

FPR is the fraction of users that we predicted would churn among everybody that
didn't churn. A small value for FPR indicates that the model is good, since it
has few false positives.

TPR is the fraction of users that we predicted would churn among everybody that
actually churned. Note that this is the same as recall, so a higher value is
better.

To use these values as metrics, we need to calculate them at many different thresholds.

**** Evaluating a model at multiple thresholds

Let us evaluate the model at different thresholds:

#+begin_src jupyter-python :display plain
  scores = []

  thresholds = np.linspace(0, 1, 101)

  for t in thresholds:
      tp = ((y_pred >= t) & (y_val == 1)).sum()
      fp = ((y_pred >= t) & (y_val == 0)).sum()
      fn = ((y_pred < t) & (y_val == 1)).sum()
      tn = ((y_pred < t) & (y_val == 0)).sum()
      scores.append((t, tp, fp, fn, tn))

  df_scores = pd.DataFrame(scores)
  df_scores.columns = ['threshold', 'tp', 'fp', 'fn', 'tn']

  df_scores[::10]
#+end_src

#+RESULTS:
#+begin_example
       threshold   tp   fp   fn   tn
  0          0.0  297  830    0    0
  10         0.1  274  445   23  385
  20         0.2  247  305   50  525
  30         0.3  221  211   76  619
  40         0.4  197  154  100  676
  50         0.5  169  103  128  727
  60         0.6  121   62  176  768
  70         0.7   71   27  226  803
  80         0.8   17    3  280  827
  90         0.9    0    0  297  830
  100        1.0    0    0  297  830
#+end_example

Now we can compute the TPR and FPR scores for all values at once:

#+begin_src jupyter-python :results silent
  df_scores['tpr'] = df_scores.tp / (df_scores.tp + df_scores.fn)
  df_scores['fpr'] = df_scores.fp / (df_scores.fp + df_scores.tn)
#+end_src

#+begin_src jupyter-python :display plain
  df_scores[::10]
#+end_src

#+RESULTS:
#+begin_example
       threshold   tp   fp   fn   tn       tpr       fpr
  0          0.0  297  830    0    0  1.000000  1.000000
  10         0.1  274  445   23  385  0.922559  0.536145
  20         0.2  247  305   50  525  0.831650  0.367470
  30         0.3  221  211   76  619  0.744108  0.254217
  40         0.4  197  154  100  676  0.663300  0.185542
  50         0.5  169  103  128  727  0.569024  0.124096
  60         0.6  121   62  176  768  0.407407  0.074699
  70         0.7   71   27  226  803  0.239057  0.032530
  80         0.8   17    3  280  827  0.057239  0.003614
  90         0.9    0    0  297  830  0.000000  0.000000
  100        1.0    0    0  297  830  0.000000  0.000000
#+end_example

We can plot them:

#+begin_src jupyter-python :file figures/figure4-01.png
  plt.plot(df_scores.threshold, df_scores.tpr, label='TPR')
  plt.plot(df_scores.threshold, df_scores.fpr, label='FPR')
  plt.legend()

  plt.xlabel('Threshold')
  plt.ylabel('Rate')
#+end_src

#+RESULTS:
:RESULTS:
: Text(0, 0.5, 'Rate')
[[file:figures/figure4-01.png]]
:END:

Both TPR and FPR start at 100%: if the threshold is 0.0%, everyone is predicted to
churn, which means that everyone that does churn is correctly predicted to churn
(TPR is 100%) and everyone that doesn't churn is incorrectly predicted to churn
(FPR is 100%).

As the threshold grows, both rates go down, but in different ways. Ideally, the
FPR should go down fast: the predicted churn probability should be small for
those that do not churn. The TPR should go down slowly (or ideally not at all):
the churn probability for those that do churn should be high.

**** Random baseline model

A random model outputs a random score between 0 and 1 regardless of the input
values. Implementing it is easy. Let's first create a function to calculate TPR
and FPR:

#+begin_src jupyter-python :results silent
  def tpr_fpr_dataframe(y_val, y_pred):
      scores = []

      thresholds = np.linspace(0, 1, 101)

      for t in thresholds:
        tp = ((y_pred >= t) & (y_val == 1)).sum()
        fp = ((y_pred >= t) & (y_val == 0)).sum()
        fn = ((y_pred < t) & (y_val == 1)).sum()
        tn = ((y_pred < t) & (y_val == 0)).sum()
        scores.append((t, tp, fp, fn, tn))

      df_scores = pd.DataFrame(scores)
      df_scores.columns = ['threshold', 'tp', 'fp', 'fn', 'tn']

      df_scores['tpr'] = df_scores.tp / (df_scores.tp + df_scores.fn)
      df_scores['fpr'] = df_scores.fp / (df_scores.fp + df_scores.tn)

      return df_scores
#+end_src

Now the model:

#+begin_src jupyter-python :display plain
  np.random.seed(1) # fix random seed for reproducibility
  y_rand = np.random.uniform(0, 1, size=len(y_val))
  df_rand = tpr_fpr_dataframe(y_val, y_rand)
  df_rand[::10]
#+end_src

#+RESULTS:
#+begin_example
       threshold   tp   fp   fn   tn       tpr       fpr
  0          0.0  297  830    0    0  1.000000  1.000000
  10         0.1  268  745   29   85  0.902357  0.897590
  20         0.2  235  662   62  168  0.791246  0.797590
  30         0.3  200  591   97  239  0.673401  0.712048
  40         0.4  167  523  130  307  0.562290  0.630120
  50         0.5  138  436  159  394  0.464646  0.525301
  60         0.6  105  348  192  482  0.353535  0.419277
  70         0.7   83  254  214  576  0.279461  0.306024
  80         0.8   49  177  248  653  0.164983  0.213253
  90         0.9   31   81  266  749  0.104377  0.097590
  100        1.0    0    0  297  830  0.000000  0.000000
#+end_example

Let's plot them:

#+begin_src jupyter-python :file figures/figure4-02.png
  plt.plot(df_rand.threshold, df_rand.tpr, label='TPR')
  plt.plot(df_rand.threshold, df_rand.fpr, label='FPR')
  plt.legend()
#+end_src

#+RESULTS:
:RESULTS:
: <matplotlib.legend.Legend at 0x7fb5089cabe0>
[[file:figures/figure4-02.png]]
:END:


With a random model, both TPR and FPR decrease in a straight line: at a
threshold of e.g., 0.4, the model predicts 40% non-churn and 60% churn. Now,
both TPR and FPR are at 60%: TPR is at 60% because 60% of customers are
correctly classified as churning; FPR is at 60% because 60% of non-churning
customers are incorrectly predicted as churning.

**** The ideal model

The ideal model always makes correct predictions. We assume an *ideal ranking*
model, which always scores churning customers higher than non-churning
customers. If we sort such a model, non-churning customers always precede
churning customers.

To create such a model, we can create an ordered set of target variables and a
set of predictions that goes from 0 to 1:

#+begin_src jupyter-python :results silent
  num_neg = (y_val == 0).sum()
  num_pos = (y_val == 1).sum()

  y_ideal = np.repeat([0, 1], [num_neg, num_pos])
  y_pred_ideal = np.linspace(0, 1, num_neg + num_pos)

  df_ideal = tpr_fpr_dataframe(y_ideal, y_pred_ideal)
#+end_src

#+begin_src jupyter-python :display plain
  df_ideal[::10]
#+end_src

#+RESULTS:
#+begin_example
       threshold   tp   fp   fn   tn       tpr       fpr
  0          0.0  297  830    0    0  1.000000  1.000000
  10         0.1  297  717    0  113  1.000000  0.863855
  20         0.2  297  604    0  226  1.000000  0.727711
  30         0.3  297  492    0  338  1.000000  0.592771
  40         0.4  297  379    0  451  1.000000  0.456627
  50         0.5  297  267    0  563  1.000000  0.321687
  60         0.6  297  154    0  676  1.000000  0.185542
  70         0.7  297   41    0  789  1.000000  0.049398
  80         0.8  226    0   71  830  0.760943  0.000000
  90         0.9  113    0  184  830  0.380471  0.000000
  100        1.0    1    0  296  830  0.003367  0.000000
#+end_example

#+begin_src jupyter-python :file figures/figure4-03.png
  plt.plot(df_ideal.threshold, df_ideal.tpr, label='TPR')
  plt.plot(df_ideal.threshold, df_ideal.fpr, label='FPR')
  plt.legend()
#+end_src

#+RESULTS:
:RESULTS:
: <matplotlib.legend.Legend at 0x7fb50892bac0>
[[file:figures/figure4-03.png]]
:END:

At a threshold of .74, the model flips: below it, we always correctly classify
all churning customers as churning, so that TPR is at 100%. At the same time,
some non-churning customers are classified as churning, so FPR is >0%.

The threshold of 0.74 is the idea situation, where all churning customers are
correctly classified as churning and no false positives occur.

At thresholds higher than 0.74, all non-churning customers are correctly
classified, hence FPR is 0%. But we start incorrectly classifying churning
customers as non-churning.

**** ROC curve

To get the ROC curve, we plot the TPR and FPR against each other:

#+begin_src jupyter-python :file figures/figure4-04.png
  plt.figure(figsize=(5, 5)) # make the plot square

  plt.plot(df_scores.fpr, df_scores.tpr, label='Model')
  plt.plot(df_rand.fpr, df_rand.tpr, label='Random')
  plt.plot(df_ideal.fpr, df_ideal.tpr, label='Ideal')

  plt.xlabel('False Positive Rate')
  plt.ylabel('True Positive Rate')

  plt.legend()
#+end_src

#+RESULTS:
:RESULTS:
: <matplotlib.legend.Legend at 0x7fb508916190>
[[file:figures/figure4-04.png]]
:END:

In the random model, the ROC curve is more or less a straight line. In the ideal
model, the TPR is 100% and the FPR 0%, making (0,1) the ideal spot. Because in
the calculation of the ROC curve, the TPR is 100% regardless of the FPR (we
always 'predict' all positives to be positives), we get the curve as shown.
(Note, for the ideal model, the curve does not really make sense; only the ideal
spot at (0,1) does.)

In an actual model, the ROC curve should always be between these two lines. The
closer to the ideal curve, the better.

Note that we do not need to generate the ideal and random models every time,
because their ROC curves are always the same. It's common to include a simple
straight line to represent the random model in a plot, the ideal curve is
usually left out. The position (0,1) is simply called the "ideal spot".

So we only need the following code:

#+begin_src jupyter-python :file figures/figure4-05.png
  plt.figure(figsize=(5, 5)) # make the plot square

  plt.plot(df_scores.fpr, df_scores.tpr)
  plt.plot([0, 1], [0, 1])

  plt.xlabel('False Positive Rate')
  plt.ylabel('True Positive Rate')
#+end_src

#+RESULTS:
:RESULTS:
: Text(0, 0.5, 'True Positive Rate')
[[file:figures/figure4-05.png]]
:END:

Obviously, Scikit-learn can compute the ROC curve for us:

#+begin_src jupyter-python :file figures/figure4-06.png
  from sklearn.metrics import roc_curve

  fpr, tpr, thresholds = roc_curve(y_val, y_pred)

  plt.figure(figsize=(5, 5))
  plt.plot(fpr, tpr, label='model')
  plt.plot([0,1], [0,1], label='random')
  plt.legend()

  plt.xlabel('False Positive Rate')
  plt.ylabel('True Positive Rate')
#+end_src

#+RESULTS:
:RESULTS:
: Text(0, 0.5, 'True Positive Rate')
[[file:figures/figure4-06.png]]
:END:

This curve is identical to the one above.

By plotting two models on the same plot, it's easy to see which of the two is
better. The one that is closer to the ideal curve is the better model.

**** The AUC

The AUC (*area under curve*) is a measure for the quality of a model. It
quantifies how close the ROC curve is to the ideal model.

If we take the area of the plot to be 1✕1, the AUC for the ideal model is 1
(i.e., the full area), while the AUC of the random model is 0.5. Any actual
model should have an AUC between 0.5 and 1, with higher values being better. 0.9
indicates a fairly good model, 0.8 is OK, 0.7 is not very performant and 0.6 is
poor.

The AUC can be computed using the =auc= function from =sklearn.metrics=:

#+begin_src jupyter-python
  from sklearn.metrics import auc
  auc(df_scores.fpr, df_scores.tpr)
#+end_src

#+RESULTS:
: 0.8219058050383352

An AUC of 0.82 is fairly good.

Scikit-learn also provides a function that takes care of computing the TPR and
FPR, =roc_auc_score=:

 #+begin_src jupyter-python
   from sklearn.metrics import roc_auc_score
   roc_auc_score(y_val, y_pred)
 #+end_src

 #+RESULTS:
 : 0.85175643655678

The AUC has a nice probabilistic interpretation: it's the probability that a
randomly selected positive example has a higher score than a randomly selected
negative example. This is a useful metric, because it allows us to understand
the model in fairly simple terms: an AUC of 1.0 means that all positive examples
are ranked higher than all negative examples. For such a model, one can find a
perfect threshold: one that always makes the correct prediction.

For a model that makes random predictions, the AUC is 0.5: the chance that a
positive example is ranked higher than a negative example is just as large as
the other way around.

*** Parameter tuning

The validation scheme used in the previous sections is a so-called hold-out
validation scheme. This means that part of the data is kept back for validation.
This, however, means that we validate the model on the held-out data. it doesn't
guarantee that it works well for other data points.

**** K-fold cross validation

If we split the data set into, e.g., three parts, we can train the model on two
parts and validate on the third and repeat this process three times. This yields
three different validation scores.

To make training and validation easier, we create functions to perform these
tasks:

#+begin_src jupyter-python :results silent
  def train(df, y):
      cat = df[categorical + numerical].to_dict('records')

      dv = DictVectorizer(sparse=False)
      dv.fit(cat)

      X = dv.transform(cat)

      model = LogisticRegression(solver='liblinear')
      model.fit(X, y)

      return dv, model


  def predict(df, dv, model):
      cat = df[categorical + numerical].to_dict('records')

      X = dv.transform(cat)
      y_pred = model.predict_proba(X)[:, 1]

      return y_pred
#+end_src

Scikit-learn provides a class for K-fold cross validation:

#+begin_src jupyter-python :results silent
  from sklearn.model_selection import KFold

  kfold = KFold(n_splits=10, shuffle=True, random_state=1)

  aucs = []

  for train_idx, val_idx in kfold.split(df_train_full):
      df_train = df_train_full.iloc[train_idx]
      df_val = df_train_full.iloc[val_idx]

      y_train = df_train.churn.values
      y_val = df_val.churn.values

      dv, model = train(df_train, y_train)
      y_pred = predict(df_val, dv, model)

      auc = roc_auc_score(y_val, y_pred)
      aucs.append(auc)
#+end_src

#+begin_src jupyter-python
  aucs
#+end_src

#+RESULTS:
| 0.85175643655678 | 0.841878094059406 | 0.8565353886018969 | 0.8287959838696404 | 0.8270626550868486 | 0.838145188145188 | 0.8386356235753827 | 0.8275537634408603 | 0.8424188528234772 | 0.8567106988000404 |

With a list of AUCs, we can do some statistics:

#+begin_src jupyter-python :results output
  print('auc = %0.3f ± %0.3f' % (np.mean(aucs), np.std(aucs)))
#+end_src

#+RESULTS:
: auc = 0.841 ± 0.011

This gives us an idea of the average performance of the model and also of its
*volatility*: how far the model may deviate from its average performance. The
smaller the deviations, the more stable the model.

**** Finding best parameters

K-Fold cross validation can be used to fine-tune parameters: train the model
with different parameters and use K-fold cross validation to determine the best
set of parameters.

As an example, the logistic regression model can take a parameter =C= that sets
the amount of regularisation. We can experiment with varying this variable.
First, we modify =train= to take an additional argument =C=:

#+begin_src jupyter-python :results silent
  def train(df, y, C):
      cat = df[categorical + numerical].to_dict('records')

      dv = DictVectorizer(sparse=False)
      dv.fit(cat)

      X = dv.transform(cat)

      model = LogisticRegression(solver='liblinear', C=C)
      model.fit(X, y)

      return dv, model
#+end_src

We can now loop over different values for C:

#+begin_src jupyter-python :results silent
  nfolds = 10
  kfold = KFold(n_splits=nfolds, shuffle=True, random_state=1)

  Cs = []

  for C in [0.001, 0.01, 0.1, 0.5, 1, 10]:
      aucs = []

      for train_idx, val_idx in kfold.split(df_train_full):
          df_train = df_train_full.iloc[train_idx]
          df_val = df_train_full.iloc[val_idx]

          y_train = df_train.churn.values
          y_val = df_val.churn.values

          dv, model = train(df_train, y_train, C=C)
          y_pred = predict(df_val, dv, model)

          auc = roc_auc_score(y_val, y_pred)
          aucs.append(auc)

      Cs.append([C, np.mean(aucs), np.std(aucs)])

  df_Cs = pd.DataFrame(Cs)
  df_Cs.columns = ['C', 'mean', 'std dev']
#+end_src

Let's check the results:

#+begin_src jupyter-python :display plain
  round(df_Cs, 3)
#+end_src

#+RESULTS:
:         C   mean  std dev
: 0   0.001  0.821    0.017
: 1   0.010  0.838    0.012
: 2   0.100  0.840    0.011
: 3   0.500  0.841    0.011
: 4   1.000  0.841    0.011
: 5  10.000  0.835    0.010

In choosing a regularisation amount to use, one should look at the highest
possible mean but at the same time at the lowest possible standard deviation.
The numbers in the book deviate a bit from the ones here, but as in the book,
0.5 seems to be the best choice. 1.0 gives the same mean and standard deviation,
but in general it's better to keep the regularisation constant as small as
possible: it means that the weights in the model are smaller, which in turn
means there is a better chance that the model will behave well with real data.

As a final step, let us test the model with C=0.5 against the test data, which
we've held out entirely:

#+begin_src jupyter-python :results output
  y_train = df_train_full.churn.values
  y_test = df_test.churn.values

  dv, model = train(df_train_full, y_train, C=0.5)
  y_pred = predict(df_test, dv, model)

  auc = roc_auc_score(y_test, y_pred)

  print('auc = %.3f' % auc)
#+end_src

#+RESULTS:
: auc = 0.857

The score here is even slightly better, but that may be random chance. It's not
something to worry about.


** Exercises

*** Calculate and plot precision and recall for different threshold values.

The following code (copied from above) calculates the values of the confusion
matrix for different thresholds. (Note: this code block should be run after
evaluating [[src:ch4-setup-code]], otherwise the =model= refers to an incorrect
LogisticRegression model.)

#+begin_src jupyter-python :display plain
  y_pred = model.predict_proba(X_val)[:,1]

  scores = []

  thresholds = np.linspace(0, 1, 101)

  for t in thresholds:
      tp = ((y_pred >= t) & (y_val == 1)).sum()
      fp = ((y_pred >= t) & (y_val == 0)).sum()
      fn = ((y_pred < t) & (y_val == 1)).sum()
      tn = ((y_pred < t) & (y_val == 0)).sum()
      scores.append((t, tp, fp, fn, tn))

  df_scores = pd.DataFrame(scores)
  df_scores.columns = ['threshold', 'tp', 'fp', 'fn', 'tn']

  df_scores[::10]
#+end_src

#+RESULTS:
#+begin_example
       threshold   tp   fp   fn   tn
  0          0.0  297  830    0    0
  10         0.1  274  445   23  385
  20         0.2  247  305   50  525
  30         0.3  221  211   76  619
  40         0.4  197  154  100  676
  50         0.5  169  103  128  727
  60         0.6  121   62  176  768
  70         0.7   71   27  226  803
  80         0.8   17    3  280  827
  90         0.9    0    0  297  830
  100        1.0    0    0  297  830
#+end_example

Calculate precision and recall and add them to the dataframe:

#+begin_src jupyter-python :display plain
  df_scores['precision'] = df_scores['tp'] / (df_scores['tp'] + df_scores['fp'])
  df_scores['recall'] = df_scores['tp'] / (df_scores['tp'] + df_scores['fn'])

  df_scores[::10]
#+end_src

#+RESULTS:
#+begin_example
       threshold   tp   fp   fn   tn  precision    recall
  0          0.0  297  830    0    0   0.263531  1.000000
  10         0.1  274  445   23  385   0.381085  0.922559
  20         0.2  247  305   50  525   0.447464  0.831650
  30         0.3  221  211   76  619   0.511574  0.744108
  40         0.4  197  154  100  676   0.561254  0.663300
  50         0.5  169  103  128  727   0.621324  0.569024
  60         0.6  121   62  176  768   0.661202  0.407407
  70         0.7   71   27  226  803   0.724490  0.239057
  80         0.8   17    3  280  827   0.850000  0.057239
  90         0.9    0    0  297  830        NaN  0.000000
  100        1.0    0    0  297  830        NaN  0.000000
#+end_example

*** Precision/Recall tradeoff

Plotting the results of the previous exercise:

#+begin_src jupyter-python :file figures/figure4-07.png
  plt.plot(df_scores.threshold, df_scores.precision, label='precision')
  plt.plot(df_scores.threshold, df_scores.recall, label='recall')
  plt.legend()

  plt.xlabel("Threshold")
#+end_src

#+RESULTS:
:RESULTS:
: Text(0.5, 0, 'Threshold')
[[file:figures/figure4-07.png]]
:END:

Finding the point where precision and recall intersect:

#+begin_src jupyter-python :display plain
  df_scores['difference'] = (df_scores['precision'] - df_scores['recall']).abs()
  df_scores.loc[df_scores['difference'] == min(df_scores['difference'])]
#+end_src

#+RESULTS:
:     threshold   tp   fp   fn   tn  precision    recall  difference
: 47       0.47  182  113  115  717   0.616949  0.612795    0.004155

*** F1-score

F1 = 2 · P · R / (P + R)

#+begin_src jupyter-python :display plain
  df_scores['f1'] = 2 * df_scores['precision'] * df_scores['recall'] / (df_scores['precision'] + df_scores['recall'])

  df_scores[::10]
#+end_src

#+RESULTS:
#+begin_example
       threshold   tp   fp   fn   tn  precision    recall  difference        f1
  0          0.0  297  830    0    0   0.263531  1.000000    0.736469  0.417135
  10         0.1  274  445   23  385   0.381085  0.922559    0.541474  0.539370
  20         0.2  247  305   50  525   0.447464  0.831650    0.384186  0.581861
  30         0.3  221  211   76  619   0.511574  0.744108    0.232534  0.606310
  40         0.4  197  154  100  676   0.561254  0.663300    0.102046  0.608025
  50         0.5  169  103  128  727   0.621324  0.569024    0.052300  0.594025
  60         0.6  121   62  176  768   0.661202  0.407407    0.253795  0.504167
  70         0.7   71   27  226  803   0.724490  0.239057    0.485433  0.359494
  80         0.8   17    3  280  827   0.850000  0.057239    0.792761  0.107256
  90         0.9    0    0  297  830        NaN  0.000000         NaN       NaN
  100        1.0    0    0  297  830        NaN  0.000000         NaN       NaN
#+end_example

#+begin_src jupyter-python :display plain
  df_scores.loc[df_scores['f1'] == df_scores['f1'].max()]
#+end_src

#+RESULTS:
:     threshold   tp   fp   fn   tn  precision    recall  difference       f1
: 45       0.45  189  123  108  707   0.605769  0.636364    0.030594  0.62069

*** AU PR

The AU PR (Area under Precision-Recall curve) is a better measure of a model's
accuracy when the dataset is highly unbalanced (say, 1000 negatives to 1
positive). The precision-recall curve is obtained by plotting recall on the
x-axis and precision on the y-axis. (Note: the =no_skill= line is taken from [[https://machinelearningmastery.com/roc-curves-and-precision-recall-curves-for-imbalanced-classification/][ROC
Curves and Precision-Recall Curves for Imbalanced Classification]].)

#+begin_src jupyter-python :file figures/figure4-08.png
  from sklearn.metrics import precision_recall_curve

  precision, recall, thresholds = precision_recall_curve(y_val, y_pred)

  plt.figure(figsize=(5, 5))
  plt.plot(recall, precision, label='model')
  no_skill = len(y_val[y_val==1]) / len(y_val)
  plt.plot([0,1], [no_skill, no_skill], label='no skill')
  plt.legend()

  plt.xlabel('Recall')
  plt.ylabel('Precision')
#+end_src

#+RESULTS:
:RESULTS:
: Text(0, 0.5, 'Precision')
[[file:figures/figure4-08.png]]
:END:


* Chapter 5: Deploying Machine Learning Models
:PROPERTIES:
:header-args:jupyter-python+: :session mlbc5 :kernel mlbc-3mO1CerA-py3.9
:END:

** Setup

We use the model that we created in chapters 3 and 4:

#+NAME: src:ch5-setup-code
#+begin_src jupyter-python :results silent
  import numpy as np
  import pandas as pd

  from sklearn.model_selection import train_test_split
  from sklearn.feature_extraction import DictVectorizer
  from sklearn.linear_model import LogisticRegression

  from matplotlib import pyplot as plt

  from mlutils import clean_alphanum_data

  df = pd.read_csv('../data/telco-customer-churn.csv')

  clean_alphanum_data(df)

  df.churn = (df.churn == 'yes').astype(int)

  df_train_full, df_test = train_test_split(df, test_size=0.2, random_state=1)
  df_train, df_val = train_test_split(df_train_full, test_size=0.2, random_state=11)

  y_train = df_train.churn.values
  y_val = df_val.churn.values

  del df_train['churn']
  del df_val['churn']

  categorical = ['gender', 'seniorcitizen', 'partner', 'dependents',
                 'phoneservice', 'multiplelines', 'internetservice',
                 'onlinesecurity', 'onlinebackup', 'deviceprotection',
                 'techsupport', 'streamingtv', 'streamingmovies',
                 'contract', 'paperlessbilling', 'paymentmethod']
  numerical = ['tenure', 'monthlycharges', 'totalcharges']

  train_dict = df_train[categorical + numerical].to_dict('records')

  dv = DictVectorizer(sparse=False)
  dv.fit(train_dict)

  X_train = dv.transform(train_dict)

  model = LogisticRegression(solver='liblinear', random_state=1)
  model.fit(X_train, y_train)

  val_dict = df_val[categorical + numerical].to_dict('records')
  X_val = dv.transform(val_dict)
#+end_src

We have the following customer:

#+begin_src jupyter-python :results silent
  customer = {
      'customerid': '8879-zkjof',
      'gender': 'female',
      'seniorcitizen': 0,
      'partner': 'no',
      'dependents': 'no',
      'tenure': 41,
      'phoneservice': 'yes',
      'multiplelines': 'no',
      'internetservice': 'dsl',
      'onlinesecurity': 'yes',
      'onlinebackup': 'no',
      'deviceprotection': 'yes',
      'techsupport': 'yes',
      'streamingtv': 'yes',
      'streamingmovies': 'yes',
      'contract': 'one_year',
      'paperlessbilling': 'yes',
      'paymentmethod': 'bank_transfer_(automatic)',
      'monthlycharges': 79.85,
      'totalcharges': 3320.75,
  }
#+end_src

We can use the =predict()= function we defined earlier:

#+begin_src jupyter-python :results silent
  def train(df, y):
      cat = df[categorical + numerical].to_dict('records')

      dv = DictVectorizer(sparse=False)
      dv.fit(cat)

      X = dv.transform(cat)

      model = LogisticRegression(solver='liblinear')
      model.fit(X, y)

      return dv, model


  def predict(df, dv, model):
      cat = df[categorical + numerical].to_dict('records')

      X = dv.transform(cat)
      y_pred = model.predict_proba(X)[:, 1]

      return y_pred
#+end_src

#+begin_src jupyter-python
  df = pd.DataFrame([customer])
  y_pred = predict(df, dv, model)
  y_pred[0]
#+end_src

#+RESULTS:
: 0.06874530315219285

The probability that this customer will churn is about 7% (in the book it's 6%).

The function =predict()= is a little inefficient for a single customer (we need
to create a dataframe that is converted back into a dictionary), so let's define
a function for a single prediction:

#+begin_src jupyter-python :results silent
  def predict_single(customer, dv, model):
      X = dv.transform([customer])
      y_pred = model.predict_proba(X)[:, 1]
      return y_pred[0]
#+end_src

When we call this on our =customer=, the result should be the same:

#+begin_src jupyter-python
  predict_single(customer, dv, model)
#+end_src

#+RESULTS:
: 0.06874530315219285

** Using =pickle= to save and load the model

We can use the =pickle= module to save the model do disk. =pickle= is built into
Python. Note that we should not only save the model, but also the =DictVectorizer=.

#+begin_src jupyter-python :results silent
  import pickle

  with open('../resources/churn-model.bin', 'wb') as f_out:
      pickle.dump((dv, model), f_out)
#+end_src

To load the model again, we can use =pickle.load=:

#+begin_src jupyter-python :results silent
  with open('../resources/churn-model.bin', 'rb') as f_in:
      dv, model = pickle.load(f_in)
#+end_src

** Flask

After starting the Flask app in the =src= directory, we can access it from here:

#+begin_src jupyter-python :results silent
  import requests

  url = 'http://localhost:9696/predict'
  response = requests.post(url, json=customer)
  result = response.json()
#+end_src

Now check the result:

#+begin_src jupyter-python :results output
  print(result)
#+end_src

#+RESULTS:
: {'churn': False, 'churn_probability': 0.06874530315219285}


* COMMENT Local Variables
:PROPERTIES:
:VISIBILITY: folded
:END:
# Local Variables:
# eval: (guess-language-mode -1)
# ispell-local-dictionary: "english"
# eval: (visual-fill-column-mode -1)
# eval: (auto-fill-mode 1))
# eval: (hl-line-mode 1)
# eval: (auto-revert-mode 1)
# End:
